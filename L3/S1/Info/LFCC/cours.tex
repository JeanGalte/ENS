\documentclass{cours}

\title{Langages Formels, Calculabilité, Complexité}
\author{Mickaël Thomazo \\ \small{Lucas Larroque}}
\date{\today}

\begin{document}
\part[Langages Réguliers]{Cours 1 28/09}
\section{Langages, Automates, RegExp, Monoïdes finis}
\begin{definition}
    On appelle \emph{alphabet} un ensemble fini $\Sigma$ de lettres. \\
    On appelle \emph{mot} une suite finie de lettres. \\
    On appelle \emph{langage} un ensemble de mots
\end{definition}
\begin{definition}
    On appelle \emph{automate sur l'alphabet $\Sigma$} un graphe orienté dont les arêtes sont étiquetées par les lettres de l'alphabet $\Sigma$\\
    Formellement, c'est un quadruplet $\mathcal{A} = (Q, \Sigma, I, F, \delta)$ ou : \begin{itemize}
        \item $Q$ est un ensemble fini d'états
        \item $\Sigma$ est un alphabet
        \item $I \subseteq Q$
        \item $F \subseteq Q$
        \item $\delta : Q \times \Sigma \rightarrow 2^{Q}$
    \end{itemize}

    Un calcul de $\mathcal{A}$ sur $w = a_{0}\ldots a_{n}$ est une séquence $q_{0}\ldots q_{n}$ telle que $q_{0} \in I, \ \forall i \geq 1,\ q_{i} \in \delta(q_{i-1}, a_{i})$\\
    On appelle Langage reconnu par $\mathcal{A}$ l'ensemble $\mathcal{L}(\mathcal{A}) =  \left\{w \in \Sigma^{*} \mid \exists q_{0}\ldots q_{n} \text{ calcul de } \mathcal{A} \text{ sur } w \text{ où } q_{n} \in F\right\}$\\
    On dit que $\mathcal{A}$ est déterministe si :\begin{itemize}
        \item $\forall q, a, \left| \delta(q, a)\right| \leq 1$
        \item $\left| I\right| = 1$
    \end{itemize} 
\end{definition}
\begin{definition}
    Une expression régulière est de la forme : 
    \begin{itemize}
        \item $a \in \Sigma$ 
        \item $\emptyset$
        \item $r + r$ (+ désigne l'union : $L_1 + L_2 = \left\{w \in L_{1} \cup L_{2} \right\}$)
        \item $r \cdot r$ ($\cdot$ désigne la concaténation : $L_1 \cdot L_2 = \left\{w_{1}w_{2} \ | \ w_{1} \in L_{1}, \ w_{2} \in L_{2} \right\}$)
        \item $r^{*}$ ($*$ désigne l'étoile de Kleene, $L^{*} = \left\{ \bigodot\limits_{w \in s} w \ \mid \ s \in \bigcup\limits_{n \in \mathbb{N}} L^{n} \right\}$)
    \end{itemize}
\end{definition}

\begin{definition}[Automate des Parties]
    On pose, si $\mathcal{A} = (Q, \Sigma, I, F, \delta)$ est un automate : 
    \begin{itemize}
        \item $\hat{Q} = 2^{Q} = \left\{q_{S} \mid S \subset Q\right\}$
        \item $\hat{I} = \left\{q_{I}\right\}$
        \item $\hat{F} = \left\{q_{S} \mid S \cap F \neq \emptyset \right\}$
        \item $\hat{\delta}(q_{S}, a) = \left\{q_{S^{'}}\right\}$ avec $S^{'} = \bigcup\limits_{q \in S}\delta(q, a)$
    \end{itemize}
    Alors, $\hat{\mathcal{A}} = (\hat{Q}, \Sigma, \hat{I}, \hat{F}, \hat{\delta})$ est un automate déterministe reconnaissant $\mathcal{L}(\mathcal{A})$
\end{definition}
\begin{proof}
    On procède par double inclusion :
    \begin{itemize}
        \item $(\subset)$ On introduit un calcul de $w \in \mathcal{L}(\mathcal{A})$ sur $\hat{\mathcal{A}}$ et on vérifie par récurrence que son dernier état est final.
        \item On procède de même pour la réciproque.
    \end{itemize}
\end{proof}

\begin{definition}
    Un monoïde est un magma associatif unifère. \\
    Un morphisme de monoïde est une application $\phi : (N, \cdot_{N}) \rightarrow (M, \cdot_{M})$ telle que: \begin{itemize}
        \item $\phi(1_{N}) = 1_{M}$
        \item $\phi(n_{1}n_{2}) = \phi(n_{1})\phi(n_{2})$
    \end{itemize}
    Un langage $L$ est reconnu par $(M, \times)$ ssi il existe $P \subset M$ tel que $L = \phi^{-1}(P)$ où $\phi$ est un morphisme de $\Sigma^{*}$ dans $M$
\end{definition}

\begin{proposition}
    $L\subseteq \Sigma^{*}$ est reconnu par un automate ssi $L$ est reconnu par un monoïde fini.
\end{proposition}
\begin{proof}
    \begin{itemize}
        \item Soit $L$ reconnu par un monoïde fini $(M, \times)$. Soit $\phi$ un morphisme tel que $L = \phi^{-1}(P), \ P\subset M$. On pose $\mathcal{A} = (M, \Sigma, \left\{1\right\}, P, \delta)$ où $\delta(q, a) = q \times \phi(a)$. Alors, $\mathcal{A}$ reconnaît $L$.
        \item Soit $\mathcal{A}$, déterministe, complet, reconnaissant $L$. Pour $a \in \Sigma$, $a \rightarrow \phi_{a} : q\in Q \mapsto \delta(q, a)$ induit par induction un morphisme de $(\Sigma^{*}, \cdot)$ dans $(Q^{Q}, \circ)$. Alors, avec $P = \left\{f \in Q^{Q}\ \mid \ f(i) \in F_{\mathcal{A}}\right\}$. On a défini le monoïde des transitions de $\mathcal{A}$.
    \end{itemize}
\end{proof}

\part[Quotients et Automates Minimaux]{Cours 2 - 5/10}

\section{Lemme de Pompage}
\begin{theorem}[Lemme de Pompage/Lemme de l'Etoile]
    Si $L$ est un langage régulier, $\exists n \in \N$ 
    $\forall w \in L, \abs{w} \geq n \Rightarrow \exists x, y, z$ tels que : 
        \begin{itemize}
            \item $w = xyz$
            \item $\abs{xy} \leq n$
            \item $y \neq \epsilon$
            \item $\forall n \geq 0, xy^{n}z \in L$
        \end{itemize}
\end{theorem}
\begin{proof}
    Faire un calcul de $\mathcal{A}$ sur $w$ tel que $\abs{w} \geq n$. Celui-ci passe deux fois par le même état.
\end{proof}

\section{Langages Quotients}
\subsection{Quotients d'un Langage à Gauche}
\begin{definition}[Quotient à Gauche]
    Soit $L, K \subseteq \Sigma^{*}, u \in \Sigma^{*}$. \\
    Le quotient à gauche de $L$ par $u$ noté $u^{-1}L$ est : $\left\{v \in \Sigma^{*} \mid uv \in L\right\}$\\
    Le quotient à gauche de $L$ par $K$, $K^{-1}L$ est $\bigcup_{u \in K}u^{-1}L$
\end{definition}
\begin{proposition}
    \begin{itemize}
        \item $w^{-1}(K+L) = w^{-1}K + w^{-1}L$
        \item $(wa)^{-1}L = a^{-1}(w^{-1}L)$
        \item $w^{-1}(KL) = (w^{-1}K \cdot L) + \sum\limits_{u \in L, v \in \Sigma^{*}\\ w = uv} v^{-1}L$
    \end{itemize}
\end{proposition}

\subsection{Quotient d'un Automate à Gauche}
\begin{definition}
    On définit le quotient à gauche d'un automate par un mot $u$ comme celui obtenu en remplaçant les états initiaux par les résultats d'un calcul de l'automate sur $u$.
\end{definition}
\begin{proposition}
    $L$ est régulier si et seulement si il a un nombre fini de quotients à gauche.
\end{proposition}
\begin{proof}
    \begin{itemize}
        \item Un automate reconnaissant $L$ a au plus un quotient par état.
        \item Posons $A_{L} = \left(\Sigma, \left\{u^{-1}L \mid u \in \Sigma^{*} \right\}, I = L = \epsilon^{-1}L, F = , \delta(w^{-1}L, a) = a^{-1}(w^{-1}L)\right)$\\
        Par récurrence, le calcul de $A_{L}$ sur $w$ termine en $w^{-1}L$
    \end{itemize}
\end{proof}

\subsection{Construction de l'Automate Minimal}
\begin{definition}
    Deux états $q_{1}, q_{2}$ sont distingables si : $\exists w \in \Sigma^{*}, \delta(q_{1}, w) \in F, \delta(q_{2} \notin F)$. 
\end{definition}
\begin{proposition}
    $q_{1}$ et $q_{2}$ sont distingables s'ils n'ont pas même quotient à gauche. Si $\delta(q, a)$ est distingable $\delta(q^{'}, a)$, $q, q^{'}$ sont distingables.\\
    La relation $q, q'$ sont distingables est une relation d'équivalence. 
\end{proposition}

\part[Logique Monadique]{Cours 3 - 12/10}
\section{Langages et Logique}
\subsection{Objectif}
On associe à $w \in \Sigma^{*}$ une structure $D_{w}$ et à $L \subseteq \Sigma^{*}$ une structure $\phi_{L}$ telles que : $w \in L\setminus \left\{\epsilon\right\} \Leftrightarrow D_{w} \vdash \phi_{L}$. On se place dans le cadre de la logique du premier ordre et de la monadique du second ordre.\\

\begin{definition}
    On définit $\textsf{pos}(w) = \left\{0, \ldots, \abs{w} - 1\right\}$. On définit une signature i.e. un ensemble de relations : 
\[
    \begin{aligned}
        \forall a \in \Sigma,& \ L_{a} \text{ d'arité } 1\\
        \leq, & \text{ l'ordre strict sur } \textsf{pos}(w)\\
    \end{aligned}   
\]    
On définit alors la structure $D_{w} = \left(\textsf{pos}(w), \left\{L_{a}^{D_{w}}\right\}_{a \in \Sigma}, <_{w}\right)$
\end{definition}
\begin{remark}
    On aurait pû remplacer $<_{w}$ par $succ_{w}$, mais on perd en expressivité. 
\end{remark}

\subsection{Logique du Premier Ordre et Monadique du Second Ordre}
\begin{definition}[Logique du Premier Ordre]
    On définit par induction la logique du premier ordre.
    \begin{itemize}
        \item Constantes
        \item Variables
        \item Si $R$ est une relation d'arité $n$, $t_{i}$ des termes : $R(t_{1}, \ldots, t_{n})$ 
        \item $\lnot \phi$, $\phi_{1} \land \phi_{2}$, $\phi_{1} \lor \phi_{2}$
        \item $\forall x, \phi, \exists \phi$
    \end{itemize}
\end{definition}
On cherche à associer à $\phi : \exists x,\ (L_{0}(x) \land \forall y (y < x \rightarrow (L_{1}(y))))$, un langage $L_{\phi} = \left\{w \mid D_{w} \vdash \phi \right\}$. 
\begin{definition}{Monadique du Second Ordre}
    Sont des formules : 
    \begin{itemize}
        \item $\forall X,\ \phi$ avec $X$, variable du second ordre qui a une arité associée.
        \item $\exists X, \ \phi$ avec $X$, variable du second ordre qui a une arité associée.
        \item $(x_{1}, \ldots, x_{n}) \in X$ avec $X$ d'arité $n$. On trouve aussi une formule pour les graphes qui mettent en relation deux sommets $s, t$ :
    \end{itemize}
    On se restreint dans la suite à des variables d'arité $1$
\end{definition}

On considère un vocabulaire qui contient une relation $E$ ("arêtes d'un graphe"). On représente un graphe par $D_{G}$ l'ensemble de ses sommets et $E^{D_{G}}$ l'ensemble des arêtes de ce graphe.
\begin{example}
    On trouve alors une formule pour représenter tous les graphes $3$-coloriables : 
    \begin{equation}
        \begin{split}
            \exists X_{1}, \exists X_{2}, \exists X_{3} & \left(\forall x \left(X_{1}(x) \lor X_{2}(x) \lor X_{3}(x)\right) \right) \\ 
            & \land \left(\forall x \forall y \left(E(x, y) \rightarrow \left(\lnot \left(X_{1}(x) \land X_{1}(y)\right)\land \lnot \left( X_{2}(x) \land X_{2}(y)\right) \land \lnot \left( X_{3}(x) \land X_{3}(y)\right)\right)\right)\right)
        \end{split}
    \end{equation}    
\end{example}
    
\begin{example}
    On trouve aussi une formule pour les graphes qui mettent en relation deux sommets $s, t$. Il s'agit de trouver une relation close par successeur qui contient $s$ : 
    \[
        \forall R \left(\left[s \in R \land \forall x, y, \left(R(x) \land E(x, y)\right) \rightarrow R(y)\right] \rightarrow t \in R\right)    
    \]
\end{example}

Ainsi, on peut en déduire une méthode pour reconnaître le langage d'un automate $\mathcal{A} = \left(\left\{0, \ldots, k\right\}, \Sigma, 0, \Delta, F\right)$ avec une formule $\phi_{\mathcal{A}}$ de la monadique du second ordre.

\begin{theorem}
    Un langage $L = L(\mathcal{A})$ est régulier, si et seulement si il existe une formule $\phi = \phi_{\mathcal{A}}$ telle que $\forall w \in L, D_{w} \vdash \phi$.
\end{theorem}
\begin{proof}
    \begin{itemize}
        \item $(\Rightarrow)$ : On peut obtenir le premier élément d'un mot par la formule $\textsf{first}(x) = \forall y ((x = y)\lor x < y)$. On peut faire de même pour savoir si un couple est composé d'une paire successeur-successeuse de l'automate, ou si $x$ est la dernière lettre.\\
        On sépare les positions d'un mot selon l'état de l'automate depuis lequel on part. Il faut alors vérifier que le premier élément est bien dans un état initial, que toute transition est bien valide, qu'on est dans au moins un état avant chaque lettre, et que la dernière position est bien écrite depuis une transition vers un état acceptant. \\
        On obtient alors, en notant $k$ le nombre d'états, et $0$ l'état initial : 
        \begin{equation}
            \begin{split}
                \phi_{\mathcal{A}} : \exists X_{0}, \ldots, \exists X_{k} & \left(\bigwedge_{i \neq j} \forall x, \ \lnot \left(X_{i}(x) \land X_{j}(x)\right)\right)\\
                & \forall x \ \left(\textsf{first}(x) \rightarrow X_{0}(x)\right)\\
                & \forall x, \forall y \ \left(\textsf{succ}(x, y) \rightarrow \bigvee_{(i, a, j) \in \Delta}\left(X_{i}(x) \land L_{a}(x) \land X_{j}(y)\right)\right)\\
                & \forall x \ \left(\textsf{last}(x) \rightarrow \bigvee_{\exists j \in F \mid (i, a, j) \in \Delta} \left(X_{i}(x) \land L_{a}(x)\right)\right)
            \end{split}
        \end{equation}
        \item $(\Leftarrow)$ : On procède par induction. 
        \begin{itemize}
            \item Initialisation : On peut facilement exhiber des automates qui reconnaissent les formules atomiques : $\textsf{Sing}(X), X \subseteq Y, X \subseteq L_{a}$.
            \item Hérédité : On raisonne sur les connecteurs, et on vérifie aisément, par les propriétés de cloture des langages réguliers le résultat. Pour ce qui est de la quantification existentielle, si le langage $L$ défini par $\psi(X_{1}, \ldots, X_{n})$ sur $\Sigma\times\left\{0, 1\right\}^{n}$ est reconnu par $\mathcal{A}$. On exhibe un automate reconnu par $\phi(X_{1}, \ldots, X_{n-1}) = \exists X_{n}\psi(X_{1}, \ldots, X_{n})$, il n'a alors plus qu'a trouver une suite de $0-1$ qui définit la $n$-ième composante additionnelle et fonctionne sur $\Sigma\times\left\{0, 1\right\}^{n}$ comme $\mathcal{A}$. Pour le $\forall$, il suffit de prendre la négation du $\exists$
        \end{itemize}
    \end{itemize}
\end{proof}

\part[Langages Algébriques]{Cours 4 : 26/10}
On a déjà vu le type 3 de la hiérarchie de Chomsky : les langages réguliers. On passe aux langages algébriques, ou hors-contexte, définis par des grammaires hors-contextes.

\section{Limites des Langages Réguliers}
Le langage $\{a^{n}b^{n}\mid n\in \N\}$ n'est pas régulier. On va donc définir une classe de langage plus grande.

\subsection{Grammaires}
\begin{definition}[Grammaire hors-contexte]
    Une grammaire hors-contexte est un quadruplet $(\Sigma, V, S, R)$ où :
    \begin{itemize}
        \item $\Sigma$ est un alphabet fini
        \item $V$ est un alphabet fini disjoint de $\Sigma$
        \item $S\in V$ est un axiome
        \item $R$ une sous partie de $V \times (\Sigma \cup V)^{\star}$
    \end{itemize}    
\end{definition}

\begin{definition}
    On dit que $u$ produit (ou dérive) $v$ en une étape si il existe $\alpha, \beta, X, \gamma$ tel que : 
    \begin{itemize}
        \item $u = \alpha X \beta$
        \item $v = \alpha \gamma \beta$
        \item $X \mapsto \gamma$ est dans $R$.
    \end{itemize}
    On note ceci $u \rightarrow v$. On note $u \xrightarrow{k} v$ si $u$ produit $v$ en $k$ étapes et $u \xrightarrow{\star} v$ si il existe un $k$.
\end{definition}

\begin{definition}
    Si $G$ est une grammaire : $\hat{\mathcal{L}}_{G}(x) = \left\{w \in \left(\Sigma \cup V\right)^{\star}\mid x \xrightarrow{\star} w \right\}$
    On définit aussi $\mathcal{L}_{G}(x) = \hat{\mathcal{L}}_{G}(x) \cap \Sigma^{\star}$.
\end{definition}

Par exemple, pour la grammaire $S \rightarrow aSb + \epsilon$, on a $\hat{\mathcal{L}}_{G_{a^{n}b^{n}}} = \left\{a^{n}Sb^{n}\mid n \in \N \right\} \cup \left\{a^{n}b^{n} \mid n \in \N \right\}$.

Pour les langages de Dyck, on peut les reconnaître par : 
\begin{center}
    \begin{tabular}{c@{$\rightarrow$}c}
        $S$ & $\epsilon$ \\
        $S$ & $T S$\\
        $T$ & $(_{1} S )_{1} \mid (_{2} S )_{2} \mid \ldots \mid (_{n} S )_{n}$
    \end{tabular}
\end{center}

\begin{remark}
    Le langages reconnu par $T$ est le langage de Dyck primitif. 
\end{remark}

\subsection{Langages Algébriques et Clôture}
\begin{proposition}
    On appelle algébrique un langage reconnu par une grammaire algébrique.
    \begin{center}
        \begin{tabular}{llp{6cm}}
            \toprule
            Langages Réguliers & Langages Algébriques & \\
            \midrule
            Clos par Union & Clos par Union & On prend l'union des règles de grammaires : $S \rightarrow S_{1}\ S_{2}$, en faisant attention à disjoindre les symboles non-terminaux\\
            Clos par Concaténation & Clos par Concaténation & On prend la concaténation des règles de grammaire : $S \rightarrow S_{1} \cdot S_{2}$, en faisant attention à disjoindre les symboles non-terminaux\\
            Clos par Intersection & NON Clos par Intersection & \\
            Clos par Complément & \dots &\\
            Clos par Etoile de Kleene & Clos par Etoile de Kleene & $S \rightarrow S S_{1} \mid \epsilon$\\
            \bottomrule         
        \end{tabular}
    \end{center}
\end{proposition}

\begin{theorem}[Intersection Algébrique-Régulier]\label{thm:capalgreg}
    Si $L_{1}$ est algébrique et $L_{2}$ est régulier, alors $L_{1} \cap L_{2}$ est algébrique.
\end{theorem}

\begin{definition}[Forme Normale de Chomsky]\label{thm:fnc}
    Une grammaire $G = \left(\Sigma, V, S, R\right)$ est sous forme normale de chomsky si toutes ses règles de grammaire sont de la forme : 
    \begin{itemize}
        \item $X \rightarrow a$
        \item $X \rightarrow X_{1}X_{2}$
        \item $S \rightarrow \epsilon$
    \end{itemize}
    avec $X \in V$ et $X_{1}, X_{2} \in V \setminus \left\{S\right\}$.
\end{definition}
\begin{theorem}
    Pour tout langage algébrique $L$, il existe $G$ sous forme normale de Chomsky telle que $L_{G}(S) = L$.
\end{theorem}
\begin{definition}
    On dit que $x$ est accessible depuis $S$ s'il existe $\alpha, \beta \in \left(\Sigma \cup V\right)^{\star}$ tels que $S \xrightarrow{\star} \alpha X \beta$.\\
    On dit que $x$ est productif si il existe $w \in \Sigma^{\star}$ tel que $X \xrightarrow{\star} w$.
    On dit que $x$ est utile s'il est accessible et productif.
\end{definition}

\begin{lemma}\label{lemme1chomskygrammar}
    Pour toute grammaire $G$, il existe $G^{'}$ telle que $L(G) = L(G^{'})$ et $G^{'}$ ne contient que des symboles accessibles.
\end{lemma}
\begin{proof}
    Soit $G^{'}$ obtenue en retirant tous les symboles non accessibles, i.e. on retire n'importe quelle règle qui contient un de ces symboles. Soit une dérivation sur $G$ à partir de $S$. Par définition de l'accessibilité, c'est une dérivation sur $G^{'}$ à partir de $S$ donc $L(G) \subseteq L(G^{'})$. Puisque toute production de $G^{'}$ est une production de $G$, on a bien le résultat.
\end{proof}

\begin{lemma}\label{lemme2chomskygrammar}
    Pour toute grammaire $G$, il existe $G^{'}$ telle que $L(G) = L(G^{'})$ ne contient que des symboles utiles.
\end{lemma}
\begin{proof}
    On marque les variables productives. Par récurrence, on trouve que $X$ est productive si $X \rightarrow w$ où $w$ est un mot sur $\Sigma$ union l'ensemble des variables productives.\\
    En prenant $V^{'}$ l'ensemble des variables productives de $G$, $R^{'} = R \cap V^{'} \times \left(\Sigma \cup V^{'}\right)^{\star}$. On a bien le résultat par les mêmes arguments que ci dessus.
\end{proof}

\begin{proof}[Preuve du théorème sur la FNC \ref{thm:fnc}]
    On utilise, dans cet ordre, \ref{lemme2chomskygrammar} puis \ref{lemme1chomskygrammar}, pour se ramener à n'avoir que des états utiles.\\
    Puis, on introduit de nouvelle règles : 
    \begin{itemize}
        \item (TERM) : On introduit de nouveaux terminaux : Si $X \rightarrow a X b$, on écrit : 
        \begin{itemize}
            \item $X \rightarrow N_{a} X N_{b}$
            \item $N_{a} \rightarrow a$
            \item $N_{b} \rightarrow b$
        \end{itemize}
        \item (INIT) : On introduit un nouvel axiome : $S^{'} \rightarrow S$
        \item (BIN) : On simplifie la règle : $X\rightarrow X_{1}\ X_{2} \ \ldots \ X_{n}$ pour $n \geq 3$.
        On introduit $X_{2}^{'}, \ldots, X_{n}^{'}$ de nouveaux non-terminaux et les règles : 
        \begin{itemize}
            \item $X\rightarrow X_{1} \ X_{2}^{'}$
            \item $\forall i, X_{i}^{'} \rightarrow X_{i} \ X_{i+1}^{'}$
        \end{itemize}
        \item ($\epsilon$) : On simplifie $X_{1} \rightarrow X\ X_{2} \ X \ X_{3} \ X $ en introduisant à la place : 
        \begin{itemize}
            \item $X_{1} \rightarrow X \ X_{2} \ X \ X_3$
            \item $X_{1} \rightarrow X \ X_{2} \ X_3 \ X$
            \item Et ainsi de suite pour chaque règle où on peut choisir $X = \epsilon$.
        \end{itemize}
        \item (UNIT) : On va simplifier $X \rightarrow Y$, en remplaçant toute apparition de $X$ dans une expression par $Y$. 
    \end{itemize}
    En choisissant correctement l'ordre des règles, on a bien le résultat. 
\end{proof}

\begin{proof}[Preuve du théorème sur l'Intersection \ref{thm:capalgreg}]
    On se donne une grammaire $G = \left(\Sigma, S, V, R\right)$ produisant $L_{1}$ et un automate $\mathcal{A} = \left(Q, \Sigma, I, F, \delta\right)$ reconnaissant $L_{2}$.\\
    On passe notre grammaire $G$ sous forme normale de Chomsky, i.e. les productions de $G$ sont sous la forme : 
    \begin{itemize}
        \item $S \rightarrow \epsilon$
        \item $X \rightarrow X_{1}\ X_{2}$
        \item $X \rightarrow a$
    \end{itemize}
    On va construire une grammaire et des terminaux $(X_{p, q})_{\forall X\in V, p\in Q, q \in Q}$ tel que : $\mathcal{L}(X_{p, q}) = \mathcal{L}(X) \cap \mathcal{L}_{2}(p \rightarrow q)$. On introduit les règles : 
    \begin{itemize}
        \item Si $X \rightarrow a \in R$, $X_{p, q} \rightarrow a$ si et seulement si $\delta(p, a) = q$.
        \item Si $X \rightarrow X_{1}\ X_{2} \in R$, $\forall p, q, q', X_{p, q} \rightarrow X_{p, q'} \ X_{q', q}$.
        \item On introduit un nouvel axiome $S^{'}$ par $S^{'} \rightarrow S_{p, q}$ pour tous $p, q$.
    \end{itemize}
    On a bien défini une grammaire $G^{'}$.
    
    Soit $w \in L_{1} \cap L_{2}$. Si $w = \epsilon$, c'est bon. 
    Sinon, on a alors un parmi :
    \begin{itemize}
        \item $S\rightarrow a$ et un état final $F$ sur lequel un calcul sur $w$ dans $\mathcal{A}$ termine, d'où $S^{'}\rightarrow S_{I, F}$ dans $G^{'}$ par construction. D'où $S_{I,F} \rightarrow a$ car $\delta(I, a) = F$, car $a\in L_{2}$.
        \item $S \rightarrow X_{1}\ X_{2}$, avec $X_{1} \rightarrow w_{1}$ et $X_{2} \rightarrow w_{2}$. $\mathcal{A}$ passe de $i$ à $q_{1}$ en lisant $w_{1}$ puis que $q_{1}$ à $F$ en lisant $w_{2}$ : $S\rightarrow X_{1_{i, q_{1}}}\ X_{2_{q_{1}, F}}$.
    \end{itemize}
    On obtient alors bien le résultat par induction.
\end{proof}

\begin{definition}
    On appelle arbre de dérivation un arbre étiqueté par $\left(\Sigma \cup V\right)$ tel que : 
    \begin{itemize}
        \item La racine est étiquetée par $S$
        \item Si un noeud étiqueté par $X$ a $k$ enfants étiquetés par $a_{1}, \ldots, a_{k}$ éléments de $\left(\Sigma \cup V\right)$, alors $X \rightarrow a_{1}\ \cdots \ a_{k} \in R$. Le mot associé est la concaténation des étiquettes des feuilles. 
    \end{itemize}
    
    Une grammaire est dite ambigue lorsqu'il existe un mot qui possède au moins deux arbres de dérivation syntaxique possible. Un langage est innéramment ambigu si toute grammaire qui le reconnaît est ambigu. 
\end{definition}

\part[Automates à Pile]{Cours 5 : 9/11}



\part[Machines de Turing]{Cours 6 : 16/11}
\section{Définitions}
\subsection{Décision}
\begin{definition}[Problèmes de Décision]
    Un problème de décision est un langage $L \subseteq \Sigma^{\star}$ sur l'alphabet $\Sigma$.
\end{definition}
\begin{example} 
    On écrit un problème sous cette forme : 
    \begin{itemize}
        \item Entrée : Un graphe non orienté $G$
        \item Sortie : Vrai ssi $G$ est $3$-coloriable
    \end{itemize}
    Passer d'une forme à l'autre est un problème d'encodage.
\end{example}

\subsection{Machine de Turing Déterministe à une Bande}
Prenons $L = \left\{w \# w \mid w \in \left\{0, 1\right\}^{\star}\right\}$. Une machine de Turing contient une mémoire, qu'on représente par une bande, et une tête de lecture et d'écriture, qui peut accéder à une case, et la remplir ou d'une lettre, ou d'un blanc. Ici, par exemple, on peut lire le premier caractère à gauche, s'en souvenir, l'effacer, lire le premier caractère à droite, le comparer au caractère lu à gauche, s'arrêter si c'est différent, l'effacer et continuer sinon...

\begin{definition}[Machine de Turing]
    Une machine de Turing est un uplet $\left(Q, \Sigma, \Sigma \subseteq \Gamma, \delta, q_{0}, q_{accept}, q_{reject}\right)$ où :
    \begin{itemize}
        \item $Q$ est un ensemble d'états
        \item $\Sigma$ est un alphabet
        \item $\Gamma$ est un alphabet (caractères sur la bande)
        \item $\delta : Q \times \Gamma \rightarrow Q \times \Gamma \times \left\{\leftarrow, \rightarrow\right\}$ est une fonction de transition.
        \item $\textvisiblespace \in \Gamma \setminus \Sigma$ est un symbole blanc.
    \end{itemize}

    Une configuration $w_{1}qw_{2}$ où $w_{1}, w_{2} \in \Gamma^{\star}$, $q\in Q$. 
\end{definition}

\begin{definition}
    La configuration initiale est $q_{0}w$. Une configuration acceptante est $w_{1}q_{accept}w_{2}$ et une configuration rejetante est $w_{1}q_{reject}w_{2}$.\\
    Si on est dans une configuration $w_{1}aqbw_{2}$, on utilise donc la transition $\delta(q, b) = q^{'}, b^{'} \leftarrow$, et on atterit dans la configuration $w_{1}q^{'}ab^{'}w_{2}$. On note cela $w_{1}aqbw_{2} \vdash w_{1}q^{'}qb^{'}w_{2}$.
\end{definition}

\begin{definition}
    $\mL(T) = \left\{w \in \Sigma^{*}a\mid \exists C_{accept}, q_{0}w \vdash^{*} C_{accept}\right\}$
\end{definition}

\begin{remark}
    Si à un moment, il n'y a plus de transition possible, cela revient à rejeter le résultat.
\end{remark}

\begin{definition}
    Soit $M$ une machine de Turing, on dit que : $M$ décide $L$ si :
    \begin{itemize}
        \item Tout calcul est fini
        \item $\mL(M) = L$
    \end{itemize}
    $M$ reconnaît $L$ si $\mL(M) = L$.\\
    $L$ est décidable (récursivement énumérable) s'il existe une TM qui décide (reconnaît) $L$.
\end{definition}

\subsection{Extensions}
On peut avoir plusieurs bandes, mais cela n'apporte pas d'expressivité.

\begin{definition}[Machines de Turing non-déterministes]
    C'est une machine de Turing pour laquelle $\delta : Q \times \Gamma \rightarrow 2^{Q} \times \Gamma \times \left\{\leftarrow, \rightarrow\right\}$
\end{definition}

\begin{proposition}
    Le non-déterminisme n'apporte pas d'expressivité.
\end{proposition}
\begin{proof}
    On fait un BFS sur l'arbre des calculs possibles, sur une TM avec 3 bandes.
\end{proof}


\subsection{Machine de Turing Universelle}
\begin{definition}[Machine de Turing Universelle]
    Une TM universelle est une machine qui permet de simuler, étant donné un encodage, une machine de Turing.    
\end{definition}

On peut par exemple encoder une TM $(Q, \Sigma, \Gamma, \delta, q_{0}, q_{accept}, q_{reject})$ et un encodage $\scalar{w}$ d'un input sur une bande par le code :
\[
    \abs{Q}_{binaire} \# \abs{\Sigma} \# \ldots \# \abs{\Gamma} \# a, q, a^{'}, q^{'}, \rightarrow, \#, \ldots, \scalar{w}
\]
On se donne ensuite une seconde bande sur laquelle on va effectuer les calculs.


\section{Limites - 1ère Partie}
\subsection{indécidabilité}
En réalité, tous les langages ne sont pas décidables : 
\begin{proposition}
    Le langage $A_{TM} = \left\{\scalar{M}, \scalar{w} \mid M \text{ accepte } w\right\}$ n'est pas décidable.
\end{proposition}

\begin{proof}
    S'il était décidable, soit $D$ une TM qui décide $A_{TM}$. Soit $D^{'}(\scalar{M})$ telle que si $D(\scalar{M}, \scalar{M})$ accepte, $D^{'}$ rejette et si $D(\scalar{M},\scalar{M})$ rejette, $D^{'}$ accepte. Alors, $D^{'}(\scalar{D^{'}})$ accepte si et seulement si il rejette. Contradiction.
\end{proof}

\begin{proposition}
    Le problème de l'arrêt $H_{TM} = \left\{\scalar{M}\mid M \text{ s'arrête sur le mot vide}\right\}$ est indécidable. 
\end{proposition}

\subsection{Propriétés de Langages}
\begin{definition}
    Une propriété de langage est un ensemble $\mathcal{P}$ de codes de machine de Turing, tq $\forall M_{1}, M_{2}$, $\scalar{M_{1}} \in \mathcal{P} \wedge \mL(M_{1}) = \mL(M_{2}) \Leftrightarrow \scalar{M_{2}} \in \mathcal{P}$. \\
    Une propriété est non triviale si : $\exists M_{1}, \ \scalar{M_{1}} \notin \mathcal{P}$ et $\exists M_{2}, \ \scalar{M_{2}}$.
\end{definition}

\begin{theorem}[Rice]
    Toute propriété de langage non triviale est indécidable.
\end{theorem}

\begin{proof}
    Cf plus tard    
\end{proof}

\begin{proposition}[Réduction de Turing]
    Supposons que $A$ décide $L$. Pour décider $L^{'}$, on construit $B$ utilisant $A$ comme sous-outil. Alors :
    \begin{itemize}
        \item Si $L$ est décidable, $L^{'}$ est décidable
        \item Si $L^{'}$ est indécidable, $L$ est indécidable
    \end{itemize}
    On a construit : $f : \Sigma_{L} \rightarrow \Sigma_{L^{'}}$ telle que $w\in L \Leftrightarrow f(w) \in L^{'}$.
\end{proposition}


\part[Indécidabilité]{Cours 7 : 23/11}

\section{Problèmes Indécidables}
\subsection{Théorème de Rice}
\begin{theorem}[Rice]
    Toute propriété de langage non triviale est indécidable.
\end{theorem}

\begin{proof}
    Supposons que $M_{\emptyset} \notin P$ avec $L\left(M_{\emptyset}\right) = \emptyset$. Soit $M_{1}$ tel que $\scalar{M_{1}} \in P$. On cherche $M_{M_{1}, M, x}$ de langage $L = \emptyset$ si $M$ ne reconnait pas $X$, $L(M_{1})$ sinon. On la définit ainsi, en notant $Y$ l'entrée : \\
    \begin{itemize}
        \item On simule $M$ sur $X$.
        \item Si $M$ rejette $X$, on rejette $Y$.
        \item Sinon, on simule $M_{1}$ sur $Y$. 
    \end{itemize}
\end{proof}

\subsection{Problèmes des Correspondances de Post}
\begin{definition}
    On appelle une tuile un objet de la forme : $\left[\begin{array}{c}u_{1} \\ v_{1} \end{array}\right]$ où $u_{1}, v_{1} \in \Sigma^{\star}$ 
\end{definition}

\begin{definition}[$PCP$]
    Etant données plusieurs tuiles, on cherche à les concaténer pour obtenir la même suite de lettres en haut de la tuile et en bas. On définit aussi le MPCP, un problème modifié où on fixe la première tuile.
\end{definition}

\begin{definition}[$Mot$]
    Le problème du mot consiste à renvoyer vrai si et seulement si une machine accepte un mot.
\end{definition}

\begin{proposition}
    Le problème $PCP$ est indécidable.
\end{proposition}
\begin{proof}
    \begin{enumerate}
        \item On réduit d'abord $PCP$ à $MPCP$ : On rajoute un symbole hors de l'alphabet considéré avant chacune des lettres des $u_{i}$, autour des lettres de $v_{1}$ et après les lettres de $v_{i}, i \geq 2$. On rajoute de plus une tuile de la forme $\left[\begin{array}{c}\$\$ \\ \cdot\$\end{array}\right]$.
        \item On réduit maintenant $MPCP$ à $PCP$ : On construit des tuiles ainsi
        \begin{itemize}
            \item La première paire $u_{1} = \$q_{0}w\$$ et $v_{1} = \$$
            \item Une paire $u_{a} = a$ et $v_{a} = a$ pour tout $a \in \Gamma$ pour recopier cette lettre
            \item Une paire $u = \$$, $v=\$$ pour passer à la configuration suivante
            \item Une paire $u = \$$ et $v = \#\$$ pour passer à la configuration suivante en ajoutant un $\#$ implicite à la fin de la configuration
            \item Une paire $u_{\tau} = pa$ et $v_{\tau} = bq$ pur toute transition $\tau = p, a \rightarrow (q, b, \rightarrow)$ de $M$
            \item Une paire $u_{\tau} = cpa$ et $v_{\tau} = qcb$ pur toute transition $\tau = p, a \rightarrow (q, b, \leftarrow)$ de $M$ et toute lettre $c \in \Gamma$.
            \item Une paire $u = aq_{+}$, $v = q_{+}$ et une paire $u = q_{accept}a$, $v = q_{accept}$ pour toute lettre $a \in \Gamma$ afin de réduire la configuration une fois l'état $q_{accept}$ atteint.
            \item Une paire $u = q_{accept}\$$ et $v = \epsilon$ pour terminer.        
        \end{itemize}
        Sous forme de dominos : 
        \[
            \left[\begin{array}{c}
                \$q_{0}w\$ \\ \$
            \end{array}\right], \left[\begin{array}{c}
                a \\ a
            \end{array}\right], \left[\begin{array}{c}
                b \\ b
            \end{array}\right], \ldots, \left[\begin{array}{c}
                \# \\ \#
            \end{array}\right], \left[\begin{array}{c}
                \$ \\ \#\$
            \end{array}\right]
        \]
        et :
        \[   
            \left[\begin{array}{c}
                pa \\ bq
            \end{array}\right], \ldots,
            \left[\begin{array}{c}
                cpa \\ qcb
            \end{array}\right], \ldots, 
            \left[\begin{array}{c}
                aq_{accept} \\ q_{accept}
            \end{array}\right], \ldots,
            \left[\begin{array}{c}
                q_{accept}a\\ q_{accept}
            \end{array}\right], \ldots,
            \left[\begin{array}{c}
                q_{accept}\$ \\ \epsilon
            \end{array}\right]
        \]
    \end{enumerate}
\end{proof}

\begin{theorem}
    Décider de la vacuité de l'intersection de deux langages algébriques n'est pas décidable.
\end{theorem}
\begin{proof}
    Soit une instance de $PCP$ donnée par deux suites $u_{1}, \ldots, u_{m}$, $v_{1}, \ldots, v_{m}$ sur un alphabet $\Sigma$.\\
    On introduit un alphabet formé de $m$ nouvelles lettres n'appartenant pas à $\Sigma$ et on définit 
    \[
        L_{u} = \left\{u_{i_{1}}u_{i_{2}}\ldots u_{i_{n}}a_{i_{n}}a_{i_{n - 1}}\ldots a_{i_{1}}\mid n \geq 0, 1 \leq i_{k} \leq m\right\}\\ 
        L_{u^{'}} \left\{wa_{i_{n}}a_{i_{n-1}}\ldots a_{i_{1}}\mid n \geq 0, w \in \Sigma^{\star}, w \neq u_{i_{1}}\ldots u_{i_{n}}\right\}
    \]
    Ces deux langages sont engendrés respectivement par :
    \[
        S \rightarrow \sum_{i = 1}^{n}u_{i}Sa_{i} + \epsilon
    \]
    et : 
    \[
        \begin{aligned}
            S \rightarrow & \sum_{i = 1}^{n} u_{i}Sa_{i} + \sum_{1 \leq i \leq m, \abs{u} = \abs{u_{i}}, u \neq u_{i}} uRa_{i} + \sum_{1 \leq i \leq m, \abs{u} < \abs{u_{i}}} uTa_{i} + \sum_{1 \leq i \leq m, b \in \Sigma} u_{i}bVa_{i}\\
            R \rightarrow & \sum_{i = 1}^{n} Ra_{i} + \sum_{b \in \Sigma} bR + \epsilon\\
            T \rightarrow & \sum_{i = 1}^{n} Ta_{i} + \epsilon\\
            V \rightarrow & \sum_{b \in V}bV + \epsilon
        \end{aligned}    
    \]
    On a donc réduit l'intersection de ces grammaires à PSP.
\end{proof}

\begin{proposition}
    Les problèmes suivants sont indécidables : 
    \begin{itemize}
        \item Décision de l'Ambiguïté d'une grammaire
        \item Egalité des langages de deux grammaires
        \item Totalité du langage d'une grammaire (vacuité de son complémentaire)
    \end{itemize}
\end{proposition}


\part[Classes de Complexité]{Cours 8 : 30/11}
\section{Temps d'un Calcul et Premières Classes}
\subsection{Définitions}
Dans la suite on se donne une machine de Turing (non nécessairement déterministe) avec une bande d'entrée, une bande de sortie et $k$ bandes de travail.
\begin{definition}
    Pour un calcul $\gamma$ $q_{0}w \rightarrow Oq_{1}w \rightarrow \cdots \rightarrow C_{n}$ sur un mot $w$ on définit son temps comme $n$, on définit alors : \[t_{M}(w) = \max_{\gamma} t_{M}(\gamma)\\ t_{M}(n) = \max_{\abs{w} = n}t_{M}(w)\]
    De même, on définit son espace comme $\max{\abs{C_{i}}}$ et alors : 
    \[
        s_{M}(w) = max_{\gamma} s_{M}(\gamma)\\
        s_{M}(n) = \max_{\abs{w} = n}s_{M}(w)
    \]
\end{definition}

On définit alors :
\begin{definition}
    \begin{itemize}
        \item \textsc{DTime}$(f(n))$ est l'ensemble des problèmes résolubles en temps $\O(f(n))$ par une machine déterministe
        \item \textsc{NDTime}$(f(n))$ est l'ensemble des problèmes résolubles en temps $\O(f(n))$ par une machine non-déterministe
    \end{itemize}
\end{definition}

\begin{definition}
    On définit :
    \[
        \textsc{P} = \bigcup_{k \geq 0} \textsc{Time}(n^{k}) \ \    \textsc{NP} = \bigcup_{k \geq 0} \textsc{NTime}(n^{k})\\
        \textsc{ExpTime} = \bigcup_{k \geq 0} \textsc{Time}(2^{n^{k}}) \ \ \textsc{NExpTime} = \bigcup_{k \geq 0} \textsc{NTime}(2^{n^{k}})
    \]
    et de même en espace.
\end{definition}

\subsection{Inclusions et Accélération}
\begin{theorem}[Linear Speed Up Theorem]
    Soit $k \geq 0$ un entier, et soit $\M$ une machine de Turing. Si $n = \O(t_{M}(n))$ alors il existe une TM $\M^{'}$ équivalente à $\M$ telle que $t_{\M^{'}} \leq \frac{t_{\M}(n)}{k}$
\end{theorem}
\begin{proof}
    On opère la transformation $\Sigma^{'} = \Sigma^{k}$.
\end{proof}

\begin{proposition}
    On a les inclusions suivantes : 
    \[
        \comp{P} \subseteq \comp{NP} \subseteq \comp{PSpace} \subseteq \comp{ExpTime} \subseteq \comp{NExpTime} \subseteq \comp{ExpSpace}
    \]
\end{proposition}

\begin{proposition}[Théorème du Gap]
    Si $g$ est calculable, il existe $f$ calculable telle que $\comp{DTime}(f(n)) = \comp{DTime}(g(f(n)))$.
\end{proposition}

\subsection{Fonctions Constructibles}
\begin{definition}
    On dit que $f$ est constructible en temps si : 
    \begin{itemize}
        \item $f(n) \geq n$
        \item $\exists$ une machine de Turing qui sort sur sa bande de sortie $1^{f(n)}$\footnote{On parle ici du mot $1\ldots 1$ $f(n)$ fois} en temps $\O(f(n))$ sur l'entrée $1^{n}$
    \end{itemize}
    On dit que $f$ est constructible en espace si :
    \begin{itemize}
        \item $f(n) \geq \log n$
        \item $\exists$ une machine de Turing qui sort $1^{f(n)}$ sur sa bande de sortie en espace $\O(f(n))$ sur l'entrée $1^{n}$
    \end{itemize}
\end{definition}

Pour justifier la bonne définition des classes de complexité $\comp{DTime}(f(n))$ en supposant $f$ constructible. On va alors construire $f(n)$ et limiter à ce nombre le nombre d'étapes du calcul. On évite dans le $\max$ de la définition du temps et de l'espace les calculs qui bouclent indéfiniment/qui ne sont pas bornés.

\begin{theorem}
    Si $f(n) = o(g(n))$ et $g$ est constructible en espace, alors : 
    \[
        \comp{Dspace}(f(n)) \subsetneq \comp{Dspace}(g(n))
    \]
\end{theorem}
\begin{proof}
    Montrons qu'il existe $L \in \comp{DSpace}(g(n)) \setminus \comp{DSpace}(f(n))$ : Sur l'entrée $M, w$, on va : 
    \begin{itemize}
        \item Calculer $g(\abs{\scalar{M, w}})$ et marquer ce nombre de cases.
        \item Simuler $M$ sur $M, w$ pendant $g(\abs{\scalar{M, w}})$ étapes
        \item Si la simulation arrive au bout, on inverse le résultat, sinon on rejette
    \end{itemize}
    On note $L$ le langage reconnu ci-dessus. On a alors : 
    \begin{itemize}
        \item $L \in \comp{DSpace}(g(n))$ car $g(n) \geq \log n$ et que l'encodage d'un mot $w$ se fait en $\O(\log \abs{w})$
        \item Supposons maintenant qu'il existe $\hat{M}$ qui calcule $L$ en $\O(f(n))$. Alors en calculant $\hat{M}(\hat{M}, w)$ : si $M$ s'arrête en moins   
    \end{itemize}
\end{proof}

\part[NP-Complétude]{Cours 9 : 7/12}
\section{NP-Complétude}

\subsection{Vérification}
\begin{definition}
    Un vérificateur en temps polynomial pour un langage $L$ est une machine déterministe $\mathcal{V}$ qui accepte des entrées de la forme $\scalar{w, c}$ en temps polynomial en $\abs{w}$ telle que $L = \left\{w \mid \exists c, \ \scalar{w, c} \in L(\mathcal{V})\right\}$
\end{definition}

\begin{theorem}
    Un langage $L$ est dans la classe $NP$ si et seulement si il existe un vérificateur polynômial pour $L$. 
\end{theorem}


\subsection{Réduction}
\begin{definition}
    Soient $A$ et $B$ des problèmes codés par $L_{A}$ et $L_{B}$ sur les alphabets $\Sigma_{A}$ et $\Sigma_{B}$. Une réduction polynomiale de $A$ à $B$ est une fonction calculable en temps polynomial par une machine de Turing déterministe telle que : 
    \[
        w \in L_{A} \Leftrightarrow f(w) \in L_{B}
    \]
    On note ceci : $A \leq_{P} B$.
\end{definition}

\begin{proposition}
    Si $A \leq_{P} B$ et $B \in P$ alors $A\in P$ 
\end{proposition}

\subsection{Complétude}
\begin{definition}
    Un problème $A$ est dit $\comp{D}$-difficile si tout problème $B$ de $\comp{D}$ se réduit à $A$ en temps polynomial. S'il est de plus dans $\comp{D}$, il est dit $\comp{D}$-complet.
\end{definition}

\begin{proposition}
    Si $A$ est $\comp{D}$-difficile, et si $A \leq_{P} B$ alors $B$ est $\comp{D}$-difficile. 
\end{proposition}


\subsection{Théorème de Cook-Levin}
\begin{definition}
    Le problème SAT est le problème de la satisfiabilité d'une formul de calcul propositionnel. Le problème 3SAT couvre le cas où cette formule est en forme normale conjonctive avec au plus trois littéraux par clause. 
\end{definition}

\part[Précisions sur la Complétude]{Cours 10 : 14/12}
\section{Précision sur la complétude}
\subsection{FPT}
\begin{definition}
    Un langage $L \subset \Sigma^{\star} \times \N$ est \textsc{Fixed Parameter Tractable} s'il existe un algo qui tourne en $f(k)n^{\O(1)}$ et décide $L$
\end{definition}

\begin{definition}
    $L$ se $\comp{Fpt}$-réduit vers $L$ s'il existe $f, g$ tel que : 
    \begin{itemize}
        \item $(x, k) \in L \Leftrightarrow \left(f(x, k), g(x, k)\right) \in L^{'}$
        \item $\forall x, g(x, k) \leq g^{'}(k)$
        \item $g(x, k)$ est calculable en temps qqch
    \end{itemize}
\end{definition}

\subsection{DP}
\begin{definition}
    Un langage est $\comp{DP}$ s'il est l'intersection d'un langage de $\comp{NP}$ et d'un de $\comp{coNP}$.
\end{definition}

\begin{definition}
    Le problème du voyageur de commerce exact, qui prend en entrée une matrice de poids et un entier $k$ et renvoie vraie si et seulement si le tour optimal est de poids $k$. 
\end{definition}

\begin{proposition}
    \textsc{Exact TSP} est \comp{DP}-complet. 
\end{proposition}

\begin{definition}
    \textsc{Sat-Unsat}($\phi_{1}, \phi_{2}$) consiste à vérifier si $\phi_{1}$ est satisfiable et si $\phi_{2}$ n'est pas satisfiable. 
\end{definition}

\begin{proposition}
    \textsc{Sat-Unsat} est $\comp{DP}$-complet
\end{proposition}
\begin{proof}
    \begin{itemize}
        \item Soit $L \in \comp{DP}, L = A\cap B$. Puisque $\textsc{Sat}$ est $\textsc{NP}$-Complet, $L$ se réduit bien à $\textsc{Sat-Unsat}$. 
        \item Il est clair par ailleurs que ce problème est bien dans $\comp{DP}$
    \end{itemize}
\end{proof}

\section{Oraclicité}
\subsection{Machines à Oracle}
\begin{definition}
    Une machine à oracle $L$ est un machine de Turing étendue par: 
    \begin{itemize}
        \item Une bande de requête
        \item Trois états $q_{?}, q_{\text{oui}}, q_{\text{non}}$
    \end{itemize}
\end{definition}

\begin{definition}
    On définit $\comp{P}^{\comp{Sat}}$ comme l'ensemble des langages qui peuvent être décidés par une machine déterministe avec oracle $\textsc{Sat}$ en temps polynomial. 
\end{definition}

\begin{proposition}
    Puisqu'on peut réduire \comp{Sat} en temps polynomial, $\comp{P}^{\comp{Sat}} = \comp{P}^{\comp{NP}}$
\end{proposition}

\subsection{Hiérarchie Polynomiale}
\begin{definition}
    On définit par récurrence : 
    \begin{itemize}
        \item $\Delta_{0}^{\comp{P}} = \Sigma_{0}^{\comp{P}} = \Pi_{0}^{\comp{P}} = \comp{P}$
        \item $\Delta_{i}^{\comp{P}} = \comp{P}^{\Sigma_{i - 1}^{\comp{P}}}$
        \item $\Sigma_{i}^{\comp{P}} = \comp{NP}^{\Sigma_{i - 1}^{\comp{P}}}$
    \end{itemize}
    On définit enfin : $\comp{PH} = \bigcup_{i}\Sigma_{i}^{\comp{P}}$
\end{definition}

\begin{proposition}
    On a : $\comp{co-NP} \subseteq \comp{P}^{\comp{NP}} \subseteq \comp{NP}^{\comp{NP}}$
    \begin{itemize}
        \item Si $P = NP$ la hiérarchie s'effondre.
        \item Si $\Sigma_{i}^{\comp{P}} = \Pi_{i}^{\comp{P}}$ alors $\comp{PH} = \Sigma_{i}^{\comp{P}}$
    \end{itemize}
\end{proposition}

\subsection{Par les machines Alternantes}
\begin{definition}
    Une machine alternante est une machine de Turing où les états sont typés entre universels et existentiels.
\end{definition}

\begin{proposition}
    On a alors : 
    \begin{itemize}
        \item $\Sigma_{i}^{\comp{P}}$ l'ensemble des langages reconnaissables par une MT alternante avec au plus $i$ alternations sur n'importe quel calcul d'état initial $\exists$.
        \item $\Pi_{i}^{\comp{P}}$ de même lorsque l'état initial est $\forall$.
    \end{itemize}
\end{proposition}

\subsection{Par certificat}
\begin{proposition}
    $L \in \Sigma_{i}^{\comp{P}}$ s'il existe $M$ une machine de Turing déterministe en temps polynomial et un polynôme $q$ tel que : 
    \[
        \forall x \in \Sigma^{\star}, x \in L \Leftrightarrow \exists u_{1} \in \left\{0, 1\right\}^{q(x)}, \forall u_{2} \in \left\{0, 1\right\}^{q(x)}, \ldots, Q_{i}u_{i} \in \left\{0, 1\right\}^{q(x)}, M(x, u_{1}, \ldots, u_{i}) = 1
    \]
\end{proposition}

\end{document}
