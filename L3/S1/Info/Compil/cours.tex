\documentclass{cours}
\title{Langage de Programmation et Compilation}
\author{Jean-Cristophe Filliâtre}
\date{\today}


\begin{document}

\part[Aperçu de la Compilation - Assembleur x86-64]{Cours 1 29/09}
\localtableofcontents
\section{Introduction à la Compilation}
Maîtriser les mécanismes de la compilation, transformation d'un langage dans un autre. Comprendre les aspects des langages de programmation.\\

\subsection{Un Compilateur}
Un compilateur est un traducteur d'un langage source vers un langage cible. Ici le langage cible sera l'asembleur. \\
Tous les langages ne sont pas compilés à l'avance, certains sont interprétés, transpilés puis interprétés, compilés à la volée, transpilés puis compilés...
Un compilateur prend un programme $P$ et le traduit en un programme $Q$ de sorte que : $\forall P, \exists Q, \forall x, \ P(x) = Q(x)$. Un interpréteur effectue un travail simple mais le refait à chaque entrée, et donc est moins efficace.\\
Exemple : le langage \textsl{lilypond} va compiler un code source en fichier .pdf. \\

\subsection{Le Bon et le Mauvais Compilateur}
On juge un compilateur à : \begin{enumerate}
    \item Sa correction
    \item L'efficacité du code qu'il produit
    \item Son efficacité en tant que programme
\end{enumerate}
\begin{quote}
    \og Optimizing compilers are so difficult to get right that we dare say that no optimizing compiler is completely error-free ! Thus, the most important objective in writing a compiler is that it is correct \fg - \textit{Dragon Book, 2006}
\end{quote}

\subsection{Le Travail d'un Compilateur}
Le travail d'un compilateur se compose : 
\begin{itemize}
    \item d'une phase d'analyse qui : 
    \begin{enumerate}
        \item reconnaît le programme à traduire et sa signification
        \item signale les erreurs et peut donc échouer
    \end{enumerate}
    \item d'une phase de synthèse qui : 
    \begin{enumerate}
        \item produit du langage cible 
        \item utilise de nombreux langages intermédiaires
        \item n'échoue pas
    \end{enumerate}
\end{itemize}
Processus : source $\rightarrow$ analyse lexicale $\rightarrow$ suite de lexèmes (tokens) $\rightarrow$ analyse syntaxique $\rightarrow$ Arbre de syntaxe abstraite $\rightarrow$ analyse sémantique $\rightarrow$ syntaxe abstraite + table des symboles $\rightarrow$ production de code $\rightarrow$ langage assembleur $\rightarrow$ assembleur $\rightarrow$ langage machine $\rightarrow$ éditeur de liens $\rightarrow$ exécutable.

\section{L'assembleur}
\subsection{Arithmétique des ordinateurs}
On représente les entiers sur $n$ bits numérotés de droite à gauche. Typiquement, $n$ vaut 8, 16, 32 ou 64. On peut représenter des entiers non signés jusqu'à $2^{n} - 1$. On peut représenter les entiers en définissant $b_{n-1}$ comme un bit de signe, on peut alors représenter $\left[-2^{n-1}, 2^{n-1}-1\right]$. La valeur d'une suite de bits est alors : $-b_{n-1}2^{n-1} + \sum_{k = 0}^{n-2} b_{k} 2^{k}$. On ne peut pas savoir si un entier est signé sans le contexte. \\
La machine fournit des opérations logiques (bit à bit), de décalage (ajout de bits 0 de poids fort, 0 de poids faible ou réplication du bit de signe pour interpréter une division), d'arithmétique (addition, soustraction, multiplication). \\
\subsection{Architecture}
Un ordinateur contient : 
\begin{itemize}
    \item Une unité de calcul (CPU) qui contient un petit nombre de registres et des capactités de calcul
    \item Une mémoire vive (RAM), composée d'un très grand nombre d'octets (8 bits), et des données et des instructions, indifférenciables sans contexte.
\end{itemize}
L'accès à la mémoire coûte cher : à 1B instructions/s, la lumière ne parcourt que 30cm entre deux instructions.\\
En réalité, il y a plusieurs (co)processeurs, des mémoires cache, une virtualisation de la mémoire\ldots\\
Principe d'exécution : un registre (\%rip) contient l'adresse de l'instruction, on lit (fetch) un ou plusieurs octects dans la mémoire, on interprète ces bits (decode), on exécute l'instruction (exectue), on modifie (\%rip) pour l'instruction suivante. En réalité, on a des pipelines qui branchent plusieurs instructions en parallèle, et on essaie de prédire les sauts conditionnels. \\
Deux grandes familles d'Architectures : CISC (complex instruction set), qui permet beaucoup d'instructions différentes mais avec assez peu de registres, et RISC (Reduced Instruction Set) avec peu d'instruction effectuées très régulièrements et avec beaucoup de registres. Ici, on utilisera l'architecture \textit{x86-64}.

\subsection{L'architecture \texttt{x86-64}}
Extension 64 bits d'une famille d'architectures compatibles Intel par AMD adoptée par Intel. Architecture à 16 registres, avec adressage sur 48 bits au moins et de nombreux modes d'adressage. \\
On ne programme pas en langage machine mais en assembleur, langage symbolique avec allocation de données globales, qui est transformé en langage machine par un assembleur qui est en réalité un compilateur. On utilise l'assembleur GNU avec la syntaxe AT\&T (la syntaxe Intel existe aussi).

\subsection{L'assembleur \texttt{x86-64}}
Pour assembler un programme assembleur, appeler \texttt{as -o file.o} puis appeler l'édition de lien avec \texttt{gcc -no-pie file.s -o exec-name}. 
On peut débuguer en ajoutant l'option \texttt{-g}.
La machine est petite boutiste (little-endian) si elle stocke les valeurs dans la RAM en commençant par le bit de poids faible, gros boutiste (big-endian) pour le poids fort. \\
Commandes : Dans cette liste, \%($r$) désigne l'adresse mémoire stockée dans $r$
\begin{itemize}
    \item \texttt{movq \$a \%b} permet de mettre la valeur $a$ dans le registre $b$
    \item \texttt{movq \%a \%b} permet de copier le registre $a$ dans le registre $b$
    \item \texttt{movq \$label \%b} permet de changer l'adresse de l'étiquette dans le registre $b$
    \item \texttt{addq \%a \%b} permet d'additionner les registres $a$ et $b$. 
    \item \texttt{incq \%r} permet d'incrémenter le registre $r$, de même pour \texttt{decq}.
    \item \texttt{negq \%r} permet de modifier la valeur de $r$ en sa négation
    \item \texttt{notq \%r} permet de modifier la valeur de $r$ en sa négation logique.
    \item \texttt{orq \%r1 \%r2} (resp. \texttt{andq} et \texttt{xorq}) permet d'affecter à $r2$, $or(r1, r2)$ (resp. $and, xor$)
    \item \texttt{salq \$n \%r}/\texttt{salq \%cl \%r} décale la valeur de $r$ de $n$ (ou $\%cl$) zéros à gauche. 
    \item \texttt{sarq} est le décalage à droite arithmétique, \texttt{shrq} le décalage à droite logique. 
    \item Le suffixe \texttt{q} désigne une opération sur 64 bits. \texttt{b} désigne 1 octet, \texttt{w} désigne 2 octets, \texttt{l} désigne 4 octets. Il faut préciser les deux extensions si celles-ci diffèrent. 
    \item \texttt{jmp label} permet de jump à une étiquette.
\end{itemize}

La plupart des opérations fositionnent des drapeaux selon leur résultat.\\
Certaines instructions : \texttt{j(suffixe)} (jump), \texttt{set(suffixe)} et \texttt{cmov(suffixe)}(move) permettent de tester des drapeaux et d'effectuer une opération selon leur valeur.

On ne sait pas combien il y a d'instructions en \texttt{x86-64}.

\subsection{Le Défi de la Compilation}
C'est de traduire un programme d'un langage de haut niveau vers ce jeu d'instruction.\\
Constat : les appels de fonctions peuvent être arbitrairement imbriqués et les registres ne suffisent pas $\Rightarrow$ on crée alors une pile car les fonctions procèdent majoritairement selon un mode LIFO.\\
La pile est stockée tout en haut, et croît dans le sens des adresses décroissantes, \texttt{\%rsp} poînte sur le sommet de la pile. Les données dynamiques sont allouées sur le tas, en bas de la zone de données. Chaque programme a l'illusion d'avoir toute la mémoire pour lui tout seul, illusion créée par l'OS. \\
En assembleur on a des facilités d'utilisation de la pile : 
\begin{itemize}
    \item \texttt{pushq \$a} push $a$ dans la pile
    \item \texttt{popq \%rdi} dépile
\end{itemize}
Lorsque $f$ (caller) appelle une fonction $g$ (callee), on ne peut pas juste \texttt{jmp g}. On utilise \texttt{call g} puis une fois que c'est terminé \texttt{ret}.\\
Mézalor tout registre utilisé par $g$ sera perdu par $f$. On s'accorde alors sur des \textbf{conventions d'appel}. Des arguments sont passés dans certains registres, puis sur la pile, la valeur de retour est passéee dans \texttt{\%rax}. 
Certains registres sont \textit{callee-saved} i.e. l'appelé doit les sauvegarder pour qu'elle survivent aux appels. Les autres registres sont dit \textit{caller-saved} et ne vont pas survivre aux appels. \\
Il faut également qu'en entrée de fonction \texttt{\%rsp + 8} doît être multiple de $16$, sinon des fonctions peuvent planter. \\
Il y a quatres temps dans un appel : 
\begin{enumerate}
    \item Pour l'appelant, juste avant l'appel : 
    \item Pour l'appelé, au début de l'appel :
    \begin{enumerate}
        \item Sauvegarde \texttt{\%rbp} puis le positionne.
        \item Alloue son tableau d'activation.
        \item Sauvegarde les registres \textit{callee-saved}.
    \end{enumerate}
    \item Pour l'appelé, à la fin de l'appel : 
    \begin{enumerate}
        \item Placer le résultat dans \texttt{\%rax}
        \item Restaure les registres sauvegardés
        \item Dépile sont tableau d'activation
        \item Exécute \texttt{ret}
    \end{enumerate}
    \item Pour l'appelant, juste après l'appel : 
    \begin{enumerate}
        \item Dépile les éventuels arguments
        \item Restaure les registres \textit{caller-saved}
    \end{enumerate}
\end{enumerate}

\part[Syntaxe abstraite, sémantique, interprètes]{Cours 2: 6/10}
\localtableofcontents

\section*{Introduction}
La signification des programmes est définie souvent de manière informelle, en langue naturelle, e.g. le langage Java.\\

\section{Sémantique Formelle}
La sémantique formelle caractérise mathématiquement les calculs décrits par un programme. C'est utile pour la réalisation d'outils (interprètes, compilateurs), et nécessaire aux raisonnements sur les programmes.\\

\subsection{Syntaxe Abstraite}
On ne peut pas manipuler un programme en tant qu'object syntaxique, on préfère utiliser la syntaxe abstraite (se déduit lors de la compilation à l'analyse syntaxique et sémantique.). On construit un arbre de syntaxe abstraite pour comprendre.\\
On définit la syntaxe abstraite par une grammaire. En OCamL, on réalise la syntaxe abstraite par des types construits. Il n'y a pas de parenthèses dans la syntaxe abstraite. On appelle sucre syntaxique toute construction de la syntaxe concrète qui n'existe pas dans la syntaxe abstraite.

C'est sur la syntaxe abstraite qu'on va définir la sémantique.

\subsection{Sémantiques Useless}
\subsubsection{Sémantique Axiomatique - Logique de Floyd-Hoare}
Tony Hoare, An axiomatic basis for computer programming, 1969, article le plus cité de l'histoire de l'informatique.\\
On caractérise les programmes par l'intermédiaire des propriétés satsfaites par les variables. On introduit le triplet \{$P$\} $i$ \{$Q$\} qui signifie, si $P$ est vraie avant l'instruction $i$, après, $Q$ sera vraie

\subsubsection{Sémantique Dénotationelle}
A chaque expression $e$, on associe sa définition $\left\lVert e\right\rVert $ qui est un objet représentant le calcul désigné par $e$. On définit cet objet récursivement.\\

\subsubsection{Sémantique Par Traduction}
On définit la sémantique d'un langage en le traduisant vers un langage dont la sémantique est connue. 

\subsection{Sémantique Opérationnelle}
La sémantique opérationnelle décrit l'enchaînement des calculs élémentaires qui mènent de l'expression à son résultat.\\
Il y a deux formes de sémantique opérationelle :
\begin{enumerate}
    \item La sémantique naturelle (big-steps semantics) : $e \twoheadrightarrow v$
    \item La sémantique par réduction (small steps semantics) $e \rightarrow e_{1} \rightarrow e_{2} \rightarrow \ldots \rightarrow v$
\end{enumerate}
On applique ça à Mini-ML (qui est Turing-Complet). 

\subsubsection{Sémantique Opérationnelle à Grand Pas}
On cherche à définir $e \twoheadrightarrow v$. On définit les valeurs parmi les constantes, les primitives non appliquées, les fonctions et les paires. \\
Une relation peut être définie comme la plus petite relation satisfaisant un ensemble d'axiomes notés $\overline{P}$ et des règles d'inférences (implications). On définit \textmd{Pair(n)} par $\overline{Pair(0)}$ et $\frac{Pair(n)}{Pair(n+2)}$. La plus petitre relation qui vérifie ces deux propriétés coïncide avec la propriété \og $n$ est un entier naturel pair \fg.\\
Une dérivation est un arbre dont les noeuds correspondent aux règles et les feuilles aux axiomes (les arbres croissent vers le haut). L'ensemble des dérivations possibles caractérise exactement la plus petite relation satisfaisant les règles d'inférence. \\
\begin{definition}
    On définit les variables libres d'une expression $e$, noté $fv(e)$ par récurrence sur $e$ avec :
    \begin{tabular}{rcl}
        $fv(x)$ &$=$&$\left\{x\right\}$\\
        $fv(c)$ &$=$&$\emptyset$\\
        $fv(op)$ &$=$&$\emptyset$\\
        $fv(\fun{x}{e})$ &$=$&$fv(e) \setminus \left\{x\right\}$\\
        $fv(e_{1} e_{2})$ &$=$&$fv(e_{1}) \cup fv(e_{2})$\\
        $fv((e_{1}, e_{2}))$ &$=$&$fv(e_{1}) \cup fv(e_{2})$\\
        $fv(\letin{x = e_{1}} e_{2})$ &$=$&$fv(e_{1}) \cup \left(fv(e_{2})\setminus \left\{x\right\}\right)$\\
        $fv(x)$ &$=$&$\left\{x\right\}$\\        
    \end{tabular}\\
    On défnit la substitution  de toute occurence libre de $x$ dans $e$ par $v$ définie par : 
    \begin{tabular}{rcl}
        $x[x\leftarrow v]$ &=& $v$\\
        $y[x \leftarrow v]$ &$=$& $y$ si $y\neq x$
    \end{tabular}
\end{definition}
On fait le choix d'une stratégie d'appel par valeur, i.e. l'argument est complètement évalué avant l'appel. \\
On a ici comme axiomes : $\overline{c \twoheadrightarrow c}$, $\overline{op \twoheadrightarrow op}$, $\overline{(\textmd{fun } x \rightarrow e) \twoheadrightarrow (\fun{x}{e})}$
et comme règles d'inférences : 
\[    
    \frac{e_{1} \twoheadrightarrow v_{1} \ \ e_{2} \twoheadrightarrow v_{2}}{(e_{1}, e_{2}) \twoheadrightarrow (v_{1}, v_{2})} \ \ \ \frac{e_{1} \twoheadrightarrow v_{1} \ \ e_{2}[x \leftarrow v_{1}] \twoheadrightarrow v}{let\ x  = e_{1} \textmd{ in } e_{2} \twoheadrightarrow v}
\]
et 
\[
  \frac{e_{1}\rrarrow(\fun{x}{e})\ \ e_{2} \rrarrow v_{2} \ \ e[x \leftarrow v_{2}] \rrarrow v}{e_{1}\ e_{2} \rrarrow v}
\]
On ajoute ensuite des règles pour les primitives, dépendant de la forme de chacune, e.g. : 
\[
  \frac{e_{1} \rrarrow + \ \ e_{2} \rrarrow (n_{1}, n_{2})\ \ n = n_{1} + n_{2}}{e_{1}\ e_{2} \rrarrow n}  
\]

Partant, on peut montrer qu'un programme s'évalue en une valeur en écrivant l'arbre de dérivation de celui-ci. \\
\begin{remark}
    Il existe des expressions sans valeur : $e = 1 2$ par exemple.
\end{remark}

On peut établir une propriété d'une relation définie par un ensemble de règles d'inférence, en raisonnant par induction sur la dérivation. Cela signifie par récurrence structurelle.
\begin{proposition}
    Si $e\twoheadrightarrow v$, alors $v$ est valeur. De plus si $e$ est close alors $v$ l'est également.
\end{proposition}
\begin{proof}
    Par induction : $\frac{e_{1} \twoheadrightarrow (\fun{x}{e}) \ \ e_{2} \twoheadrightarrow v_{2} \ \ e[x \leftarrow v_{2}] \twoheadrightarrow v}{e_{1} e_{2} \twoheadrightarrow v}$.
\end{proof}
\begin{proposition}
    Si $e \twoheadrightarrow v$ et $e \twoheadrightarrow v^{'}$, alors $v = v'$.
\end{proposition}
\begin{proof}
    Par induction. 
\end{proof}
\begin{remark}
    On a donc définit une fonction plus qu'une relation. 
\end{remark}

\subsubsection{Sémantique à Petits Pas}
La sémantique opérationnelle à petits pas remédie aux problèmes de programmes qui ne terminent pas, en introduisant une notion d'étape élémentaire de calcul $e_{1} \rightarrow e_{2}$\\
On commence par définir une relation $\rightarrow^{\epsilon}$ correspondant à une réduction en tête, au sommet de l'expression, par exemple : $(\textmd{fun } x\rightarrow e)\ v \rightarrow^{\epsilon} e[x \leftarrow v]$
On se donne également des règles pour les primitives. On réduit en profondeur en introduisant la règle d'inférence : $\frac{e_{1}\rightarrow^{\epsilon} e_{2}}{E(e_{1})\rightarrow E(e_{2})}$ où $E$ est un contexte défini par la grammaire suivante :
\begin{tabular}{crl}
    $E$ &$::=$& $\square$\\
    &|& $E e$\\
    &|& $v E$\\
    &|& $\letin{x = E} e$\\
    &|& $(E, e)$\\
    &|& $(v, E)$\\
\end{tabular}\\
Un Contexte est un terme à trou où $\square$ représente le trou. $E(e)$ dénote le contexte $E$ dans lequel $\square$ a été remplacé par $e$. La règle d'inférence permet donc d'évaluer une sous-expression. Tels que définis, les contextes impliquent ici une évaluation en appel par valeur et de gauche à droite. \\
On note $\rightarrow^{*}$ la cloture réflexive et transitive de $\rightarrow$.
\begin{definition}
    On appelle forme normale toute expression $e$ telle qu'il n'existe pas $e^{'}$ telle que : $e \rightarrow e^{'}$
\end{definition}

\subsubsection{Equivalence des Sémantiques}
\begin{theorem}
    Les deux sémantiques opérationnelles sont équivalentes pour les expressions dont l'évaluation termine sur une valeur i.e. :
    \[
        e \rrarrow v \Leftrightarrow e \rightarrow^{*} v    
    \]    
\end{theorem}
\begin{proof}
    \begin{lemma}[Passage au contexte des réductions]
        Supposons $e \rightarrow e'$, alors :        
        \begin{enumerate}
            \item $e e_{2} \rightarrow e^{'} e_{2}$
            \item $v e \rightarrow v e^{'}$
            \item $\letin{x = e} e_{2} \rightarrow \letin{x = e'} e_{2}$
        \end{enumerate}
    \end{lemma}
    \begin{itemize}
        \item $(\Rightarrow)$ On procède par induction sur la dérivation. 
        \item $(\Leftarrow)$ :
        \begin{lemma}[Evaluation des Valeurs]
           On a $v \rrarrow v$.
        \end{lemma}
        \begin{lemma}
            Si $e \rightarrow e'$ et $e' \rrarrow v$ alors $e \rrarrow v$.
        \end{lemma}
        \begin{proof}
            On commence par les réductions de tête, puis on procède par induction aux applications de contexte. 
        \end{proof}
        On a alors, par récurrence sur le nombre de pas, l'implication souhaitée. 
    \end{itemize}
\end{proof}

\subsubsection{Langages Impératifs}
Pour un langage impératif les sémantiques ci-dessus sont insuffisantes. On associe alors typiquement un état $S$ à l'expression évaluée. L'état peut être décomposé en plusieurs éléments pour modéliser par exemple une pile (des variables locales), des tas... 

\section{Interprète}
    On peut programmer un interprète en suivant les règles de la sémantique naturelle. On se donne un type pour la syntaxe abstraite des expressions et on définit une fonction correspondant à la relation $\twoheadrightarrow$\\
    Un interprète renvoie la (ou les) valeur(s) d'une expression, souvent récursivement.\\
    On peut éviter l'opération de substitution, en interprétant l'expression $e$ à l'aide d'un environnement donnant la valeur courante de chaque variable (un dictionnaire). Ceci pose problème car le résultat de $\textmd{let } x = 1 \textmd{ in fun } y \rightarrow +(x, y)$ est une fonction qui doit \og mémoriser \fg que $x = 1$.\\
    On utilise alors le module \textmd{Map} pour les environnements (c'est une \textit{fermeture}). On représente alors la valeur d'une fonction avec son environnement. \\
    Pour un interprète de la sémantique à petits pas, il vaut mieux utiliser un \textit{zipper} que de recalculer le contexte tout le temps. 

\part[Analyse Lexicale]{Cours 3 : 13/10}
\localtableofcontents
\section*{Introduction}
L'objectif est de partir du code source, une suite de caractère, pour obtenir une suite de lexèmes plus compréhensible et simple à analyse syntaxiquement

\section{Blancs}
Les blancs (espace, retour chariot, tabulation) jouent un rôle dans l'analyse lexicale, car ils permettent de séparer deux lexèmes. De nombreux blancs sont inutiles e.g. \textmd{x + 1}, et seront ignorés.\\
Les conventions diffèrent selon les langages et certains des caractères blancs peuvent être significatifs, par exemple l'indentation en python ou en Haskell, ou les retours chariots transformés en points-virgules comme en python. Les commentaires jouent le rôle de blancs.

\section{Outils pour l'analyse lexicale}
On va utiliser des expressions régulières pour décrire les lexèmes et des automates finis pour les reconnaître. On exploite en particulier la capacité à construire un automate partant d'une ou plusieurs expressions régulières.

\subsection[Expressions Régulières et Automates Finis]{Expressions Régulières et Automates Finis\footnote{Voir Cours de LFCC}} 
%TODO: ajouter un lien vers le cours. Faire un seul poly complet ? 

\subsubsection{Expressions Régulières}
\begin{definition}[Syntaxe]
    On définit la syntaxe des expressions régulières :
\begin{center}
    \begin{tabular}{c@{$\mid$}c}
        $r = $& $\emptyset$\\
        &$\epsilon$\\
        &$a \in \Sigma$\\
        &$r \cdot r$\\
        &$r + r$\\
        &$r\star$\\    
    \end{tabular}    
\end{center} 
\end{definition}

\begin{definition}[Sémantique]
    On définit alors la sémantique basée sur cette syntaxe par les langages rationnels : 
    \begin{center}
        \begin{tabular}{c@{ = }c}
            $L(\emptyset)$ &$\emptyset$\\
            $L(a)$ &$\left\{a\right\}$\\
            $L(r_{1}r_{2})$ &$L(r_{1}) \cdot L(r_{2})$\\
            $L(r_{1} + r_{2})$ &$L(r_{1}) \cup L(r_{2})$\\
            $L(r\star)$ &$\bigcup_{n \in \N} L^{n}(r)$        
        \end{tabular}
    \end{center} 
\end{definition}

Pour les constantes flottantes de CamL on a par exemple, si $d = 0 | 1 | \ldots | 9$ :
\[
    d\ d\star(.d\star \mid (\epsilon \mid .d\star)(e \mid E)(\epsilon \mid + \mid -)\ d\ d\star)  
\]
On peut alors écrire un algorithme pour savoir si une suite de caractère appartient à une regexp.
\begin{definition}[Dérivée de Brzozowski]
    On pose, pour $r$ une regexp et $c \in \Sigma$ : $\delta(r, c) = \left\{w \mid cw \in L(r)\right\}$
\end{definition}

\subsubsection{Automates Finis}
\begin{definition}[Syntaxe]
    Un automate fini est un quintuplet $(Q, \Sigma, I, F, T)$ où :
    \begin{itemize}
        \item $Q$ est un ensemble fini d'états
        \item $\Sigma$ est un ensemble fini appelé alphabets
        \item $I \subseteq Q$ est un ensemble d'états initiaux
        \item $F \subseteq Q$ est un ensemble d'états finaux
        \item $T \subseteq Q \times \Sigma \times Q$ est un ensemble de transitions
    \end{itemize}
\end{definition}

\begin{theorem}[De Kleene]
    Les expressions régulières et les automates finis définissent les mêmes langages. 
\end{theorem}
\begin{proof}
    Voir Cours de LFCC
\end{proof}

\subsection{Analyseur Lexical}

\subsubsection{Principe}

Un analyseur lexical est un automate fini pour la réunion de toutes les expressions régulières définissant les lexèmes.
Le fonctionnement de l'analyseur lexical est différent de la simple reconnaissance d'un mot par un automate car : 
\begin{itemize}
    \item Il faut décomposer un mot (le source) en une suite de mots reconnus
    \item Il peut y avoir des ambiguïtés
    \item Il faut construire les lex`emes (les états finaux contiennent des actions)
\end{itemize}

\paragraph*{Ambiguïtés}
Le mot \textmd{funx} est reconnu par l'expression régulière des identificateurs mais contient un préfixe reconnu par une autre expression régulière (\textmd{fun}) : $\Rightarrow$ On choisit de reconnaître le lexème le plus long possible.\\
Le mot \textmd{fun} est reconnu par la regexp du mot clef \textmd{fun} mais aussi par celle des identificateurs : $\Rightarrow$ On classe les lexèmes par ordre de priorité.

\paragraph*{Retour en arrière}
Un analyseur va échouer sur l'entrée $abc$ avec les trois regexp $a, ab, bc$.
L'analyseur lexical doit donc mémoriser le dernier état final rencontré, le cas échéant.\\

Lorqu'il n'y a plus de transition possible dans l'automate, de deux choses l'une :
\begin{itemize}
    \item Soit aucun état final mémorisé : échec de l'analyse lexicale
    \item Soit on a lu le préfixe $wv$ de l'entrée, avec $w$ le lexème reconnu par le dernier état final recontré : on renvoie $w$ et l'analyse lexicale redémarre avec $v$ préfixé au reste de l'entrée
\end{itemize}
En pratique, on va renvoyer dans l'analyseur lexical une fonction de calcul du prochain lexème, puisque l'analyse lexicale est faite pour l'analyse syntaxique, cf. \ref{part:AnalyseSyntaxique}

\subsubsection{Construction}
\paragraph*{L'automate de Thompson}
On construit par induction un automate compatible. 

\paragraph*{L'automate de Berry-Sethi}
On met en correspondance les lettres d'un mot reconnu et celles apparaissant dans la regexp : 
On distingue les différentes lettres de la regexp puis on construit un automate dont les états sont des ensembles de lettres. 
Pour construire les transitions de $s_{1}$ à $s_{2}$, on détermine les lettres qui peuvent apparaître après une autre dans un mot reconnu : \textmd{follow}. Pour calculer \textmd{follow}, on a besoin de savoir calculer les premières et dernières lettres d'un mot reconnu (\textmd{first} et \textmd{last}). On a alors besoin d'une dernière notion : \textmd{null}, est-ce que $\epsilon$ appartient au langage reconnu. On obtient : 
\begin{center}
    \begin{tabular}{c@{ = }c}
        \toprule
        $\textmd{null}(\emptyset)$ & \textmd{false}\\
        $\textmd{null}(\epsilon)$ & \textmd{true}\\
        $\textmd{null}(a)$ & \textmd{false}\\
        $\textmd{null}(r_{1}r_{2})$ & $\textmd{null}(r_{1}) \land  \textmd{null}(r_{2})$\\
        $\textmd{null}(r_{1}\mid r_{2})$ & $\textmd{null}(r_{1}) \lor  \textmd{null}(r_{2})$\\
        $\textmd{null}(r\star)$ & \textmd{true}\\
        \midrule
        \multicolumn{2}{c}{On en déduit : }\\
        \midrule
        $\textmd{first}(\emptyset)$ & $\emptyset$\\
        $\textmd{first}(\epsilon)$ & $\emptyset$\\
        $\textmd{first}(a)$ & $\left\{a\right\}$\\
        $\textmd{first}(r_{1}r_{2})$ & $\textmd{first}(r_{1}) \cup \textmd{first}(r_{2})$ \text{ si }$\textmd{null}(r_{1})$\\
        & $\textmd{first}(r_{1})$ sinon\\
        $\textmd{first}(r_{1}\mid r_{2})$ & $\textmd{first}(r_{1}) \cup \textmd{first}(r_{2})$\\
        $\textmd{first}(r\star)$ & $\textmd{first}(r)$\\
        \midrule
        \multicolumn{2}{c}{On définit \textmd{last} de même}\\
        \midrule
        $\textmd{follow}(c, \emptyset)$ & $\emptyset$\\
        $\textmd{follow}(c, \epsilon)$ & $\emptyset$\\
        $\textmd{follow}(c, a)$ & $\emptyset$\\
        $\textmd{follow}(c, r_{1}r_{2})$ & $\textmd{follow}(c, r_{1}) \cup \textmd{follow}(c, r_{2}) \cup \textmd{first}(r_{2})$ si $c \in \textmd{last}(r_{1})$\\
        & $\textmd{follow}(c, r_{1}) \cup \textmd{follow}(c, r_{2})$ sinon\\
        $\textmd{follow}(c, r_{1} \mid r_{2})$ & $\textmd{follow}(c, r_{1}) \cup \textmd{follow}(c, r_{2})$\\
        $\textmd{follow}(c, r\star)$ & $\textmd{follow}(c, r) \cup \textmd{first}(r)$ si $c\in \textmd{last}(r)$\\
        &$\textmd{follow}(c, r)$ sinon\\
        \bottomrule
    \end{tabular}
\end{center}
On construit alors l'automate reconnaissant $r$ en ajoutant $\#$ à la fin de $r$ : 
\begin{enumerate}
    \item L'état initial est l'ensemble $\textmd{first}(r\#)$.
    \item Tant qu'il existe un état $s$ dont on doit calculer les transitions, pour chaque $c$ de l'alphabet, on pose $s^{'}$ l'état $\bigcup_{c_{i} \in s} \textmd{follow}(c_{i}, r\#)$
    \item Les états acceptants sont ceux contenant $\#$
\end{enumerate}

\section{L'outil \textmd{ocamllex}}
\subsection{Analyseur Lexical en \textmd{ocamllex}}
Un fichier \textmd{ocamllex} porte le suffixe \textmd{.mll} et a la forme suivante : 
\begin{itemize}
    \item Code OCamL arbitraire
    \item $\textmd{rule } f_{1} = \textmd{parse} \mid \textmd{regexp1 } \{\textmd{action 1}\}$ 
    \item \dots
    \item Code OcamL arbitraire
\end{itemize}
A la compilation par \textmd{ocamllex file.mll}, on construit un fichier OCamL contenant des fonctions de types $\textmd{Lexing.lexbuf} \rightarrow \textmd{type}$ où le type de sortie dépend de l'action dans la fonction. \\

Les regexp en \textmd{ocamllex} s'écrivent sous la forme : 
\begin{center}
    \begin{tabular}{>{\textmd{}}ll}
        \toprule
        \_  & n'importe quel caractère\\
        'a' & le caractère \textmd{'a'}\\
        "foobar" & la chaîne \textmd{"foobar"} (en particulier $\epsilon = ""$)\\
        \text{[}caractères\text{]} & ensemble de caractères\\
        \text{[}\^{}caractères\text{]} & complémentaire d'un ensemble de caractères\\
        $r_{1} \mid r_{2}$ & alternative \\
        $r_{1}r_{2}$ & concaténation \\
        $r *$ & étoile\\
        $r + $ & une ou plusieurs occurences de $r$, i.e. $r r\star$\\
        $r?$ & au plus une occurence de $r$\\
        eof & fin du fichier\\
        \bottomrule         
    \end{tabular}
\end{center}
Pour remplacer la reconnaissance du lexème le plus long par celui le plus court, remplacer \textmd{parse} par \textmd{shortest}.\\
A longueur égale, c'est la règle qui apparaît en premier qui l'emporte. \\
On peut nommer la chaîne reconnue, ou des sous-chaînes reconnues par des sous-experssions régulières, à l'aide de la construction \textmd{as}.\\
On peut dans une action, rappeler récursivement l'analyseur lexical ou l'un des autres analyseurs simultanément définis. Le tampon d'analyse lexical doit être passé en argument, il est contenu dans une variable appelée \textmd{lexbuf}. Ceci est utile pour séparer les blancs, ou reconnaître les commentaires, même imbriqués. \\

Par défaut \textmd{ocamllex} contruit l'automate dans une table interprétée à l'exécution, mais l'option \textmd{-ml} construit du code CamL pur. 

\subsection{Efficacité}
Pour des raisons de stockage, et même en utilisant une table, l'automate peut prendre beaucoup de place. Il est donc préférable d'utiliser une seule expression régulière pour les identificateurs et les mots-clefs, puis de les séparer ensuite grâce à une table des mots-clefs.\\
On peut de même ne stocker que les caractères en minuscule pour être insensible à la casse.

\subsection{D'autres utilisations \textmd{ocamllex}}
On peut utiliser $\textmd{ocamllex}$ pour :
\begin{enumerate}
    \item Réunir plusieurs lignes vides consécutives en une seule
    \item Compter les occurences d'un mot dans un texte
    \item Un petit traducteur OCamL vers HTML pour embellir le source mis en ligne (mettre les mots-clefs en vert, les commentaires en rouge, numéroter les lignes \dots), le tout en moins de 100 lignes de code.
\end{enumerate}


\part[Analyse Syntaxique]{Cours 4 : 20/10}\label{part:AnalyseSyntaxique}
\section{Analyse Syntaxique}
L'objectif de l'analyse syntaxique est, à partir d'une suite de lexèmes, de construire la syntaxe abstraite, qu'on représente sous forme d'arbre. En particulier, l'analyse syntaxique doit détecter les erreurs de syntaxe et les localiser précisément, les identifier (parenthèse non fermée, etc...) voire reprendre l'analyse pour découvrir de nouvelles erreurs. On va utiliser : une grammaire non contextuelle pour décrire la syntaxe et un automate à pile pour la reconnaître. 

\section{Grammaires}
\begin{definition}
    Une grammaire non contextuelle est un quadruplet $(N, T, S, R)$ où :
    \begin{itemize}
        \item $N$ est un ensemble fini de symboles non terminaux.
        \item $T$ est un ensemble fini de symboles terminaux.
        \item $S \in N$ est le symbole de départ (axiome).
        \item $R \subseteq N \times (N \cup T)^{*}$ est un ensemble fini de règles de production.
    \end{itemize}
\end{definition}
On note les règles de dérivation sous la forme : 
\begin{equation*}
    \begin{aligned}
        &E &\rightarrow &E + E\\
        & &\mid &E*E\\
        & &\mid &(E)\\
        & &\mid &\textmd{int}
    \end{aligned}
\end{equation*}

\begin{definition}
    Un mot $u \in (N\cup T)^{*}$ se dérive en un mot $v \in (N \cup T)^{*}$ et on note $u \rightarrow v$ s'il existe une décomposition $u = u_{1}Xu_{2}$ avec $X \in N$, $X \rightarrow \beta \in R$ et $v = u_{1}\beta u_{2}$. On appelle dérivation gauche le cas où $u_{1}$ ne contient pas de mots terminaux.
    On appelle langage défini par $G$ l'ensemble des mots de $T^{*}$ dérivés de l'axiome. 
\end{definition}

\begin{definition}
    Un arbre de dériviation est un arbre dont les noeuds sont étiquetés par des symboles de la grammaire, de la manière suivante : 
    \begin{itemize}
        \item La racine est l'axiome
        \item Tout noeud interne $X$ non terminal dont les fils sont étiquetés par $\beta \in (N\cup T)^{*}$ avec $X \rightarrow \beta$ une règle de la dérivation. 
    \end{itemize}
\end{definition}

Pour un arbre de dérivation dont les feuilles forment le mot $w$ dans l'arbre infixe, on a $S \rightarrow^{\star} w$. Inversement, si $S \rightarrow^{\star} w$, on a un arbre de dérivation dont les feuilles dans l'arbre infixe forment $w$. 

\begin{definition}
    Une grammaire est ambigüe si au moins un mot admet au moins deux arbres de dérivation. Déterminer si une grammaire est ambigüe ou non n'est pas décidable.
\end{definition}
La grammaire précédente est ambigüe, comment interpréter $\textmd{int} + \textmd{int} * \textmd{int}$

On va utiliser des critères décidables suffisants pour garantir qu'une grammaire est non ambigüe, et pour lesquels on sait en outre décider l'appartenance au langage efficacement.

\section{Analyse ascendante}
On va ici lire l'entrée de gauche à droite (pas toujours le cas, cf. \textmd{CYK}) puis reconnaître des membres droits de productions pour construire l'arbre de dérvation de bas en haut : bottom-up parsing.

\subsection{Fonctionnement}
On va manipuler une pile qui est un mot de $(N \cup T)^{*}$. 
A chaque instant, on a deux actions possibles : 
\begin{itemize}
    \item Une opération de lecture (\textit{shift}) : on lit un terminal de l'entrée et on l'empile.
    \item Une opération de réduction (\textit{reduce}) : on reconnaît en sommet de pile le membre droit $\beta$ d'une production $X \rightarrow \beta$ et on remplace $\beta$ par X en sommet de pile.
\end{itemize}
Comment prendre la décision lecture / réduction ? On se sert d'un automate fini et on examine les $k$ premiers lexèmes de l'entrée, c'est l'analyse \textmd{LR(k)}, pour \og Left to right scanning, Righmost derivation\fg. En pratique, $k = 1$.
\subsection{Analyse LR}
La pile est de la forme $s_{0}x_{1}s_{1}x_{2}\ldots x_{n}s_{n}$ où $s_{i}$ est un état de l'automate et $x_{i} \in T \cup N$ comme dans un automate. 
Soit $a$ le premier lexème de l'entrée. Une table indexée par $s_{n}$ et $a$ nous indique l'action à effectuer : 
\begin{itemize}
    \item Si c'est un succès ou un échec, on s'arrête.
    \item Si c'est une lecture, on empile $a$ et l'état $s$ résultat de la transition $s_{n} \rightarrow^{a} s$ dans l'automate.
    \item Si c'est une réduction $X \rightarrow \alpha$, avec $\alpha$ de longueur $p$, on doit trouver $\alpha$ en sommet de pile : 
    \[
        s_{0}x_{1}\ldots x_{n-p}s_{n-p}\mid \alpha_{1}s_{n-p+1}\ldots \alpha_{p}s_{n}
    \]
    On dépile alors $\alpha$ et on empile $X s$ où $s_{n-p} \rightarrow^{X} s$ dans l'automate, i.e. $s_{0}x_{1}\ldots x_{n-p}s_{n-p}Xs$
\end{itemize}

En pratique on ne travaille pas avec l'automate mais avec deux tables : 
\begin{itemize}
    \item Une table d'actions ayant pour lignes les états et pour colonnes les terminaux. La case \textmd{action(s, a)} indique : 
    \begin{itemize}
        \item $\textmd{shift s'}$ pour une lecture et un nouvel état $s^{'}$
        \item $\textmd{reduce X} \rightarrow \alpha$ pour une réduction
        \item un succès
        \item un échec
    \end{itemize}
    Une table de déplacements ayant pour lignes les états et pour colonnes les non terminaux. La case $\textmd{goto(s, X)}$ indique l'état résultat d'une réduction de $X$.
\end{itemize}
On ajoute aussi un lexème spécial \# qui désigne la fin de l'entrée. On peut le voir comme l'ajout d'un nouveau non terminal $S$ qui devient l'axiome et d'une règle $S \rightarrow E \#$.
Pour créer ces tables, on utilise la famille de \textmd{yacc} (\textit{Yet Another Compiler Compiler})

\section{L'outil Menhir}
Menhir transforme une grammaire en un analyseur OCamL de type $LR(1)$. Chaque production de la grammaire est accompagnée d'une action sémantique, i.e. du code OCamL construisant une valeur sémantique (typiquement un arbre de syntaxe abstraite). Menhir s'utilise conjointement avec un analyseur lexical (typiquement \textrm{ocamllex}).\\
Un fichier Menhir a le suffixe \textmd{.mly} et a la forme suivante : 
\begin{itemize}
    \item \%{\textmd{code OCamL arbitraire} \%}
    \item \textmd{déclaration des lexèmes}
    \item \%\%
    \item \textmd{non-terminal-1 : }
    | \textmd{production} \{ \textmd{action} \}
    | \textmd{production} \{ \textmd{action} \}
    ;
    \item non-terminal-2:
    | \textmd{production} \{ \textmd{action} \}
    \item \%\%
    \item \textmd{code OCamL arbitraire}
\end{itemize}
En cas de conflits, Menhir produit deux fichiers pour expliquer d'où les conflits viennent. On peut les résoudre est d'indiquer comment choisir entre lecture et réduction. On peut donner des priorités aux lexèmes et aux productions, en fonction des règles d'associativité. Si la priorité de la production est supérieure à celle du lexème à lire, la réduction est favorisée. En cas d'égalité, l'associativité est consultée : un lexème associatif à gauche favorise la réduction et un lexème associatif à droite favorise la lecture. Par ailleurs, pour empêcher l'associativité, on peut aussi l'indiquer à Menhir, et éviter le \textit{dangling else}.

Pour que les phases suivantes de l'analyse (typiquement le typage) puissent localiser les messages d'erreur, il convient de conserver une information de localisation dans l'arbre de syntaxe abstraite. Menhir fournit cette information dans $\$startpos$ et $\$endpos$, deux valeurs du type \textmd{Lexing.position}. Cette information lui a été transmise par l'analysur lexical. (\textmd{ocamllex} ne maintient automatiquement que la position absolue dans le fichier, il faut appeler Lexing.new\_line pour chaque retour chariot.)

\section{Derrère l'outil Menhir}
\subsection{\textsc{First, Null, Follow}}
\begin{definition}[\textsc{Null}]
    Soit $\alpha \in (T \cup N)^{*}$. $\textsc{Null}(\alpha)$ est vrai si et seulement si on peut dériver $\epsilon$ à partir de $\alpha$.
\end{definition}
\begin{definition}[\textsc{First}]
    Soit $\alpha \in (T \cup N)^{*}$. $\textsc{First}(\alpha)$ est l'ensemble de tous les premiers terminaux des mots dérivés de $\alpha$, i.e. $\left\{a \in T \mid\ \exists \ w, \ \alpha \rightarrow^{\star} aw\right\}$
\end{definition}
\begin{definition}[\textsc{Follow}]
    Soit $X \in N$. $\textsc{Follow}(X)$ est l'ensemble des terminaux qui peuvent apparaître après $X$ dans une dérivation, i.e. 
    $\left\{a \in T \mid\ \exists \ u,\ w \ S \rightarrow^{\star} uXaw \right\}$.
\end{definition}

\begin{theorem}[Tarski]
    Soit $A$ un ensemble fini muni d'une relation d'ordre $\leq$ et d'un plus petit élément $\epsilon$. Toute fonction $f : A \rightarrow A$ croissante admet un plus petit point fixe. 
\end{theorem}
\begin{proof}
    Comme $\epsilon$ est le plus petit élément, $\epsilon \leq f(\epsilon)$. Par croissance, $f^{k}(\epsilon) \leq f^{k+1}(\epsilon)$ pour tout $k$. Mais $A$ étant fini, il existe un plus petit $k_{0}$ tel que $f^{k_{0}}(\epsilon) = f^{k_{0} + 1}(\epsilon)$. En le notant $a_{0}$, on a bien un point fixe de $f$. Si $b$ est un autre point fixe, par croissance, puisque $\epsilon \leq b$, on a bien le résultat. 
\end{proof}

\subsubsection{Principe du calcul de $\textsc{Null}(X)$} 
\begin{proposition}
    Pour calculer $\textsc{Null}(\alpha)$, il suffit de déterminer $\textsc{Null}(X)$ pour $X\in N$.
    On a $\textsc{Null}(X)$ ssi : 
    \begin{itemize}
        \item Il existe une production $X \rightarrow \epsilon$
        \item Il existe une production $X \rightarrow Y_{1}\ldots Y_{m}$ où $\textsc{Null}(Y_{i})$ pour tout $i$.
    \end{itemize}
    Il s'agit d'un ensemble d'équations mutuellement récursives. Autrement dit, on cherche la plus petite solution d'une équation de la forme : $\vec{V} = F(\vec{V})$.
\end{proposition}
\begin{proof}
    \begin{itemize}
        \item $\Rightarrow$ Par récurrence sur le nombre d'étapes du calcul de point fixe, on montre que si \textsc{Null}$(X)$ alors $X \rightarrow^{\star}\epsilon$
        \item $\Leftarrow$ Par récurrence sur le nombre d'étapes de la dérivation, on montre la réciproque.
    \end{itemize}
\end{proof}
Ici, on a $A = \left\{0, 1\right\}^{n}$. On munit $\{0, 1\}$ de l'ordre $0 \leq 1$ et $A$ de l'ordre point à point. On a $\epsilon = (0, \ldots, 0)$. La fonction calculant $\textsc{Null}(X)$ à partir des $\textsc{Null}(X_{i})$ est croissante, et le théorème de Tarski s'applique. On construit donc un point fixe à partir de $\epsilon$.

\subsubsection{Principe du calcul de $\textsc{First}(X)$}
De même que pour \textsc{Null} : Les équations définissant $\textsc{First}$ sont mutuellement récursives : 
\[
    \textsc{First}(X) = \bigcup_{X \rightarrow \beta} \textsc{First}(\beta)    
\]
et :  
\begin{equation*}
    \begin{aligned}
        \textsc{First}(\epsilon) &= \emptyset&\\
        \textsc{First}(a\beta) &= \left\{a\right\}&\\
        \textsc{First}(X\beta) &= \textsc{First}(X) \text{ si } \lnot\textsc{Null}(X)&\\
        \textsc{First}(X\beta) &= \textsc{First}(X) \cup \textsc{First}(\beta) \text{ si } \textsc{Null}(X)&
    \end{aligned}
\end{equation*}
On applique alors le calcul de point fixe sur $A = \mathcal{P}(T)^{n}$ muni de $\subseteq$ point à point avec $\epsilon = (\emptyset, \ldots, \emptyset)$

\subsubsection{Principe du calcul de $\textsc{Follow}(X)$}
Les équations sont : 
\[
    \textsc{Follow}(X) = \left(\bigcup_{Y \rightarrow \alpha X\beta} \textsc{First}(\beta)\right) \cup \left(\bigcup_{Y\rightarrow \alpha X \beta, \textsc{Null}(\beta)} \textsc{Follow}(Y)\right)
\]
On procède par calcul de point fixe sur le même domaine que pour \textsc{First}.

\subsection{Automate LR}
\subsubsection{$LR(0)$}
Fixons pour l'instant $k = 0$. On commence par contruire un automate asynchrone :
\begin{itemize}
    \item Les états sont des items de la forme $\left[X \rightarrow \alpha \cdot \beta\right]$ où $X\rightarrow \alpha\beta$ est une production de la grammaire. L'intuition est : \og je cherche à reconnaître $X$, j'ai déjà lu $\alpha$ et je dois encore lire $\beta$ \fg.
    \item Les transitions sont étiquetées par $T \cup N$ et sont les suivantes : 
    \begin{equation*}
        \begin{aligned}
            \left[Y \rightarrow \alpha \cdot a\beta \right] &\rightarrow^{a} \left[Y \rightarrow \alpha a \cdot \beta\right]&\\
            \left[Y \rightarrow \alpha \cdot X\beta \right] &\rightarrow^{X} \left[Y \rightarrow \alpha X \cdot \beta\right]&\\
            \left[Y \rightarrow \alpha \cdot X\beta \right] &\rightarrow^{\epsilon} \left[X \rightarrow \cdot \gamma\right] \text{ pour toute production } X \rightarrow \gamma&\\
        \end{aligned}
    \end{equation*}
\end{itemize}

On déterminise ensuite l'automate en regroupant les états reliés par des $\epsilon$-transitions. Les états de l'automate déterministe sont donc des ensembles d'items.\\
Par construction : chaque état $s$ est saturé par la propriété : si $Y \rightarrow \alpha \cdot X\beta \in s$ et si $X \rightarrow \gamma$ est une production, alors $X \rightarrow \cdot\gamma \in s$. L'état initial est celui contenant $S \rightarrow \cdot E\#$.\\

On construit alors la table $\textmd{action}$:
\begin{itemize}
    \item $\textmd{action}(s, \#) = $ succès si $\left[S \rightarrow E \cdot \#\right] \in s$
    \item $\textmd{action}(s, a) = \textmd{shift} s^{'}$ si $s\rightarrow^{a} s^{'}$
    \item $\textmd{action}(s, a) = \textmd{reduce} X \rightarrow \beta$ si $\left[X \rightarrow \beta\cdot \right] \in s$ pour tout $a$.
    \item $\textmd{échec}$ dans tous les autres cas
\end{itemize}

On construit alors la table $\textmd{goto}$ : $\textmd{goto}(s, X) = s^{'}$ si $s \rightarrow^{X} s^{'}$.

La table $LR(0)$ peut contenir deux sortes de conflits : lecture/réduction et réduction/réduction.
\begin{definition}
    Une grammaire est dite $LR(0)$ so la table ainsi construite ne contient pas de conflit.
\end{definition}
La construction $LR(0)$ engendre très facilement des conflits. On va chercher à limiter les réductions : 
on pose $\textmd{action}(s, a) = \textmd{reduce} X \beta$ si et seulement si $\left[X \rightarrow \beta\cdot\right] \in s$ et $a \in \textsc{Follow}(X)$. On obtient la classe de grammaire $S(imple)LR(1)$.

\subsubsection{$LR(1)$}
Cette classe étant restrictive, on introduit une classe de grammaires encore plus large : $LR(1)$, au prix de tables encore plus grandes. Dans l'analyse $LR(1)$, les items ont la forme : $\left[X \rightarrow \alpha \cdot \beta, a\right]$
Les transitions de l'automate $LR(1)$ non déterministe sont : 
\begin{equation*}
    \begin{aligned}
        \left[Y \rightarrow \alpha \cdot a\beta, b\right] &\rightarrow^{a} \left[Y \rightarrow \alpha a \cdot \beta, b\right]&\\\left[Y \rightarrow \alpha \cdot a\beta, b\right] &\rightarrow^{a} \left[Y \rightarrow \alpha a \cdot \beta, b\right]&\\
        \left[Y \rightarrow \alpha \cdot X\beta, b\right] &\rightarrow^{X} \left[Y \rightarrow \alpha X \cdot \beta, b\right]&\\
        \left[Y \rightarrow \alpha \cdot X\beta, b\right] &\rightarrow^{\epsilon} \left[X \rightarrow \cdot\gamma, c\right] \text{ pour tout } c \in \textsc{First}(\beta b)&
    \end{aligned}
\end{equation*}

L'état initial est celui qui contient $\left[S \rightarrow \cdot \alpha, \#\right]$. On peut déterminiser l'automate et construire la table correspondante : on introduit une action de réduction pour $(s, a)$ seulement lorsque $s$ contient un item de la forme $\left[X \rightarrow \alpha\cdot, a\right]$.

Pour des questions de puissances de calcul, on introduit la classe $LALR(1)$, lookahead LR, qui est une approximation beaucoup utilisée dans les outils de la famille \textmd{yacc}.

\part[Analyse Syntaxique 2]{Cours 5 : 27/10}
\section{Localisations}
L'outil \textmd{ocamllex} maintient, dans la structure de type \textmd{Lexing.lexbuf}, la position courante dans le texte source qui est analysé. On peut alors obtenir la localisation de la dernère chaîne reconnue par \textmd{ocamllex}. On peut utiliser ces informations pour localiser les erreurs de syntaxe, mais aussi de potentielles erreurs lexicales comme une chaîne ou un commentaire non fermé.\\
L'outil \textmd{Menhir}\footnote{L'outil \textmd{Cairn} permet de visualiser l'analyse de \textmd{Menhir}.} récupère ces informations et les fournit dans deux valeurs \textmd{\$startpos} et \textmd{\$endpos}, qui, dans une action sémantique, correspondent au début et à la fin du texte reconnu par la règle de grammaire. On peut alors stocker cette information dans l'arbre de syntaxe abstraite. 

\section{Analyse Syntaxique Elementaire}
On va ici construire un analyseur syntaxique pour des expressions arithmétiques incluant :
\begin{itemize}
    \item des constantes
    \item des additions
    \item des multiplications
    \item des parenthèses
\end{itemize}
On part d'un analyseur lexical, par exemple écrit avec \textmd{ocamllex}:
\begin{minted}{ocaml}
type token = 
    | CONST of int
    | PLUS
    | TIMES
    | LEFTPAR
    | RIGHTPAR
    | EOF
\end{minted}
et on veut obtenir un arbre de syntaxe abstraite : 
\begin{minted}{ocaml}
type expr = 
    | Const of int
    | Add of expr * expr
    | Mul of expr * expr
\end{minted}

On écrit un parser dans le fichier Menhir, puis, juste en dessous dans le fichier, l'analyseur syntaxique.

\begin{remark}
    Conseil : Commencer par écrire un pretty-printer, ici, en OcamL avec la bibliothèque \textmd{Format} :
\end{remark}

    \begin{minted}{ocaml}
        open Format
        let rec print_expr fmt = function
          | Add (e1, e2) -> fprintf fmt "%a +@ %a" print_expr e1 print_expr e2
          | e            -> print_term fmt e
        and print_term fmt = function
          | Mul (e1, e2) -> fprintf fmt "%a *@ %a" print_term e1 print_term e2
          | e            -> print_factor fmt e
        and print_factor fmt = function
          | Const n -> fprintf fmt "%d" n
          | e       -> fprintf fmt "(@[%a@])" print_expr e
    \end{minted}


L'analyseur syntaxique suit la même structure que la fonction d'affichage\footnote{Le code n'est pas complet, cf \href{https://www.lri.fr/~filliatr/ens/compil/}{page du cours}}. C'est ça, le bon conseil de Gilles Kahn : 
\begin{center}
    \begin{minted}{ocaml}
        let rec parse_expr () =
            let e = parse_term () in
            if !t = PLUS then (next (); Add (e, parse_expr ())) else e 
        and parse_term () =
            let e = parse_factor () in
            if !t = TIMES then (next (); Mul (e, parse_term ())) else e
        and parse_factor () = match !t with
            | CONST n -> next (); Const n
            | LEFTPAR -> next (); 
                let e = parse_expr () in 
                if !t <> RIGHTPAR then error ();
                next (); e
            | _ -> error ()
    \end{minted}
\end{center}
\begin{remark}
    On pourrait inclure l'analyse lexicale dans un tel code, avec d'autres fonctions récursives pour lire les constantes entières, ignorer les blancs, etc\dots\\
    Pour des opérateurs associatifs à gauche, le code sera légèrement différent mais le principe reste le même. 
\end{remark}

\section{Analyse Descendante}
\subsection{Fonctionnement}
On va procéder par expansions successives du non-terminal le plus à gauche (dérivation gauche) en partant de $S$ et en utilisant une table qui indique pour un non-terminal $X$ à expanser et les $k$ premiers caractères de l'entrée, l'expansion $X\rightarrow\beta$ à effectuer. Dans la suite, on va prendre $k = 1$, et on va noter $T(X, c)$ cette table. En pratique, on suppose qu'un symbole terminal \# dénote la fin de l'entrée, et la table indique donc également l'expansion de $X$ lorsqu'on atteint la fin de l'entrée.\\
On utilise une pile qui est un mot de $\left(N \cup T\right)^{\star}$. Initialement, la pile est réduite au symbole de départ. A chaque instant, on va ensuite examiner le sommet de la pile et le premier caractère $c$ de l'entrée: 
\begin{itemize}
    \item Si la pile est vide, on s'arrête; il y a succès ssi $c$ est \#.
    \item Si le sommet de la pile est un terminal $a$, alors $a$ doit être égal à $c$, on dépile alors $a$ et on consomme $c$; sinon on échoue.
    \item Si le sommet de la pile est un non terminal $X$, on remplace $X$ par le mot $\beta = T(X, c)$ en sommet de pile, en empilant les caractères de $\beta$ en partant du dernier; sinon on échoue
\end{itemize}

\subsection{Programmation}
Un analyseur descendant se programme en introduisant une fonction pour chaque non terminal de la grammaire. Chaque fonction examine l'entrée, et selon le cas, la consomme ou appelle récursivement les fonctions correspondant à d'autres non terminaux, selon la table d'expansion. 
\begin{remark}
    \begin{itemize}
        \item La table d'expansion n'est alors pas explicite : elle est dans le code de chaque fonction.
        \item La pile n'est pas explicite, elle est réalisée par la pile d'appels.
        \item En pratique il faut construire l'arbre de syntaxe abstraite. 
    \end{itemize}
\end{remark}

\subsection{Construction de la Table d'Expansion}
Pour décider si on réalise l'expansion $X\rightarrow\beta$ lorsque le premier caractère de l'entrée est $c$, on va chercher à déterminer si $c$ fait partie des premiers caractères des mots reconnus par $\beta$. Une difficulté se pose pour une production telle que $X\rightarrow\epsilon$, et il faut alors considérer l'ensemble des caractères qui peuvent suivre $X$. On utilise donc à nouveau les fonctions \textmd{first} et \textmd{follow} :Pour chaque production $X \rightarrow\beta$
\begin{itemize}
    \item On pose $T(X, a) = \beta$ pour tout $a \in \textmd{first}(\beta)$
    \item Si $\textmd{null}(\beta)$, on pose aussi $T(X, a) = \beta$ pour tout $a\in \textmd{follow}(X)$.
\end{itemize}
Il peut y avoir plusieurs éléments dans une même case : 
\begin{definition}
    Une grammaire est dite $LL(1)$ si, dans la table précédente, il y a au plus une production dans chaque case. 
\end{definition}
Une grammaire récursive gauche, i.e. contenant des productions de la forme : $X\rightarrow X\alpha | \beta$, ne sera jamais $LL(1)$. En effet, les \textmd{first} seront les mêmes pour ces deux productions. En particulier, la grammaire :
\begin{tabular}{c@{$\rightarrow$}c}
    $E$ & $E + T$\\
    & $T$\\
    $T$ & $T * F$\\
    & $F$\\
    $F$ & $( E )$\\
    & $\textmd{int}$\\
\end{tabular}
n'est pas $LL(1)$. Plus généralement, si une grammaire contient $X \rightarrow a\alpha + a\beta$. Il faut alors factoriser (à gauche) les productions qui commencent par le même terminal.

\section{Indentation comme Syntaxe}
Dans certains langages, l'indentation (blancs de début de ligne/alignement vertical) est utilisée pour définir la syntaxe. L'analyseur lexical introduit des lexèmes \textmd{NEWLINE} (fin de ligne), \textmd{INDENT} (quand l'indentation augmente) et \textmd{DEDENT} (quand elle diminue). Il suffit alors de les utiliser dans la grammaire du langage. 


\end{document}