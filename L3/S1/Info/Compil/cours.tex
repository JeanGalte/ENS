\documentclass{cours}
\title{Langage de Programmation et Compilation}
\author{Jean-Cristophe Filliâtre}
\date{\today}

\newcommand*{\rrarrow}{\twoheadrightarrow}
\newcommand*{\llarrow}{\twoheadleftarrow}
\newcommand*{\fun}[2]{\textmd{fun } #1 \rightarrow #2}
\newcommand*{\letval}{\textmd{let }}
\newcommand*{\letin}[1]{\textmd{let } #1 \textmd{ in }}

\begin{document}

\part[Aperçu de la Compilation - Assembleur x86-64]{Cours 1 29/09}
\localtableofcontents
\section{Introduction à la Compilation}
Maîtriser les mécanismes de la compilation, transformation d'un langage dans un autre. Comprendre les aspects des langages de programmation.\\

\subsection{Un Compilateur}
Un compilateur est un traducteur d'un langage source vers un langage cible. Ici le langage cible sera l'asembleur. \\
Tous les langages ne sont pas compilés à l'avance, certains sont interprétés, transpilés puis interprétés, compilés à la volée, transpilés puis compilés...
Un compilateur prend un programme $P$ et le traduit en un programme $Q$ de sorte que : $\forall P, \exists Q, \forall x, \ P(x) = Q(x)$. Un interpréteur effectue un travail simple mais le refait à chaque entrée, et donc est moins efficace.\\
Exemple : le langage \textsl{lilypond} va compiler un code source en fichier .pdf. \\

\subsection{Le Bon et le Mauvais Compilateur}
On juge un compilateur à : \begin{enumerate}
    \item Sa correction
    \item L'efficacité du code qu'il produit
    \item Son efficacité en tant que programme
\end{enumerate}
\begin{quote}
    \og Optimizing compilers are so difficult to get right that we dare say that no optimizing compiler is completely error-free ! Thus, the most important objective in writing a compiler is that it is correct \fg - \textit{Dragon Book, 2006}
\end{quote}

\subsection{Le Travail d'un Compilateur}
Le travail d'un compilateur se compose : 
\begin{itemize}
    \item d'une phase d'analyse qui : 
    \begin{enumerate}
        \item reconnaît le programme à traduire et sa signification
        \item signale les erreurs et peut donc échouer
    \end{enumerate}
    \item d'une phase de synthèse qui : 
    \begin{enumerate}
        \item produit du langage cible 
        \item utilise de nombreux langages intermédiaires
        \item n'échoue pas
    \end{enumerate}
\end{itemize}
Processus : source $\rightarrow$ analyse lexicale $\rightarrow$ suite de lexèmes (tokens) $\rightarrow$ analyse syntaxique $\rightarrow$ Arbre de syntaxe abstraite $\rightarrow$ analyse sémantique $\rightarrow$ syntaxe abstraite + table des symboles $\rightarrow$ production de code $\rightarrow$ langage assembleur $\rightarrow$ assembleur $\rightarrow$ langage machine $\rightarrow$ éditeur de liens $\rightarrow$ exécutable.

\section{L'assembleur}
\subsection{Arithmétique des ordinateurs}
On représente les entiers sur $n$ bits numérotés de droite à gauche. Typiquement, $n$ vaut 8, 16, 32 ou 64. On peut représenter des entiers non signés jusqu'à $2^{n} - 1$. On peut représenter les entiers en définissant $b_{n-1}$ comme un bit de signe, on peut alors représenter $\left[-2^{n-1}, 2^{n-1}-1\right]$. La valeur d'une suite de bits est alors : $-b_{n-1}2^{n-1} + \sum_{k = 0}^{n-2} b_{k} 2^{k}$. On ne peut pas savoir si un entier est signé sans le contexte. \\
La machine fournit des opérations logiques (bit à bit), de décalage (ajout de bits 0 de poids fort, 0 de poids faible ou réplication du bit de signe pour interpréter une division), d'arithmétique (addition, soustraction, multiplication). \\
\subsection{Architecture}
Un ordinateur contient : 
\begin{itemize}
    \item Une unité de calcul (CPU) qui contient un petit nombre de registres et des capactités de calcul
    \item Une mémoire vive (RAM), composée d'un très grand nombre d'octets (8 bits), et des données et des instructions, indifférenciables sans contexte.
\end{itemize}
L'accès à la mémoire coûte cher : à 1B instructions/s, la lumière ne parcourt que 30cm entre deux instructions.\\
En réalité, il y a plusieurs (co)processeurs, des mémoires cache, une virtualisation de la mémoire\ldots\\
Principe d'exécution : un registre (\%rip) contient l'adresse de l'instruction, on lit (fetch) un ou plusieurs octects dans la mémoire, on interprète ces bits (decode), on exécute l'instruction (exectue), on modifie (\%rip) pour l'instruction suivante. En réalité, on a des pipelines qui branchent plusieurs instructions en parallèle, et on essaie de prédire les sauts conditionnels. \\
Deux grandes familles d'Architectures : CISC (complex instruction set), qui permet beaucoup d'instructions différentes mais avec assez peu de registres, et RISC (Reduced Instruction Set) avec peu d'instruction effectuées très régulièrements et avec beaucoup de registres. Ici, on utilisera l'architecture \textit{x86-64}.

\subsection{L'architecture \texttt{x86-64}}
Extension 64 bits d'une famille d'architectures compatibles Intel par AMD adoptée par Intel. Architecture à 16 registres, avec adressage sur 48 bits au moins et de nombreux modes d'adressage. \\
On ne programme pas en langage machine mais en assembleur, langage symbolique avec allocation de données globales, qui est transformé en langage machine par un assembleur qui est en réalité un compilateur. On utilise l'assembleur GNU avec la syntaxe AT\&T (la syntaxe Intel existe aussi).

\subsection{L'assembleur \texttt{x86-64}}
Pour assembler un programme assembleur, appeler \texttt{as -o file.o} puis appeler l'édition de lien avec \texttt{gcc -no-pie file.s -o exec-name}. 
On peut débuguer en ajoutant l'option \texttt{-g}.
La machine est petite boutiste (little-endian) si elle stocke les valeurs dans la RAM en commençant par le bit de poids faible, gros boutiste (big-endian) pour le poids fort. \\
Commandes : Dans cette liste, \%($r$) désigne l'adresse mémoire stockée dans $r$
\begin{itemize}
    \item \texttt{movq \$a \%b} permet de mettre la valeur $a$ dans le registre $b$
    \item \texttt{movq \%a \%b} permet de copier le registre $a$ dans le registre $b$
    \item \texttt{movq \$label \%b} permet de changer l'adresse de l'étiquette dans le registre $b$
    \item \texttt{addq \%a \%b} permet d'additionner les registres $a$ et $b$. 
    \item \texttt{incq \%r} permet d'incrémenter le registre $r$, de même pour \texttt{decq}.
    \item \texttt{negq \%r} permet de modifier la valeur de $r$ en sa négation
    \item \texttt{notq \%r} permet de modifier la valeur de $r$ en sa négation logique.
    \item \texttt{orq \%r1 \%r2} (resp. \texttt{andq} et \texttt{xorq}) permet d'affecter à $r2$, $or(r1, r2)$ (resp. $and, xor$)
    \item \texttt{salq \$n \%r}/\texttt{salq \%cl \%r} décale la valeur de $r$ de $n$ (ou $\%cl$) zéros à gauche. 
    \item \texttt{sarq} est le décalage à droite arithmétique, \texttt{shrq} le décalage à droite logique. 
    \item Le suffixe \texttt{q} désigne une opération sur 64 bits. \texttt{b} désigne 1 octet, \texttt{w} désigne 2 octets, \texttt{l} désigne 4 octets. Il faut préciser les deux extensions si celles-ci diffèrent. 
    \item \texttt{jmp label} permet de jump à une étiquette.
\end{itemize}

La plupart des opérations fositionnent des drapeaux selon leur résultat.\\
Certaines instructions : \texttt{j(suffixe)} (jump), \texttt{set(suffixe)} et \texttt{cmov(suffixe)}(move) permettent de tester des drapeaux et d'effectuer une opération selon leur valeur.

On ne sait pas combien il y a d'instructions en \texttt{x86-64}.

\subsection{Le Défi de la Compilation}
C'est de traduire un programme d'un langage de haut niveau vers ce jeu d'instruction.\\
Constat : les appels de fonctions peuvent être arbitrairement imbriqués et les registres ne suffisent pas $\Rightarrow$ on crée alors une pile car les fonctions procèdent majoritairement selon un mode LIFO.\\
La pile est stockée tout en haut, et croît dans le sens des adresses décroissantes, \texttt{\%rsp} poînte sur le sommet de la pile. Les données dynamiques sont allouées sur le tas, en bas de la zone de données. Chaque programme a l'illusion d'avoir toute la mémoire pour lui tout seul, illusion créée par l'OS. \\
En assembleur on a des facilités d'utilisation de la pile : 
\begin{itemize}
    \item \texttt{pushq \$a} push $a$ dans la pile
    \item \texttt{popq \%rdi} dépile
\end{itemize}
Lorsque $f$ (caller) appelle une fonction $g$ (callee), on ne peut pas juste \texttt{jmp g}. On utilise \texttt{call g} puis une fois que c'est terminé \texttt{ret}.\\
Mézalor tout registre utilisé par $g$ sera perdu par $f$. On s'accorde alors sur des \textbf{conventions d'appel}. Des arguments sont passés dans certains registres, puis sur la pile, la valeur de retour est passéee dans \texttt{\%rax}. 
Certains registres sont \textit{callee-saved} i.e. l'appelé doit les sauvegarder pour qu'elle survivent aux appels. Les autres registres sont dit \textit{caller-saved} et ne vont pas survivre aux appels. \\
Il faut également qu'en entrée de fonction \texttt{\%rsp + 8} doît être multiple de $16$, sinon des fonctions peuvent planter. \\
Il y a quatres temps dans un appel : 
\begin{enumerate}
    \item Pour l'appelant, juste avant l'appel : 
    \item Pour l'appelé, au début de l'appel :
    \begin{enumerate}
        \item Sauvegarde \texttt{\%rbp} puis le positionne.
        \item Alloue son tableau d'activation.
        \item Sauvegarde les registres \textit{callee-saved}.
    \end{enumerate}
    \item Pour l'appelé, à la fin de l'appel : 
    \begin{enumerate}
        \item Placer le résultat dans \texttt{\%rax}
        \item Restaure les registres sauvegardés
        \item Dépile sont tableau d'activation
        \item Exécute \texttt{ret}
    \end{enumerate}
    \item Pour l'appelant, juste après l'appel : 
    \begin{enumerate}
        \item Dépile les éventuels arguments
        \item Restaure les registres \textit{caller-saved}
    \end{enumerate}
\end{enumerate}

\part[Syntaxe abstraite, sémantique, interprètes]{Cours 2: 6/10}
\localtableofcontents

\section*{Introduction}
La signification des programmes est définie souvent de manière informelle, en langue naturelle, e.g. le langage Java.\\

\section{Sémantique Formelle}
La sémantique formelle caractérise mathématiquement les calculs décrits par un programme. C'est utile pour la réalisation d'outils (interprètes, compilateurs), et nécessaire aux raisonnements sur les programmes.\\

\subsection{Syntaxe Abstraite}
On ne peut pas manipuler un programme en tant qu'object syntaxique, on préfère utiliser la syntaxe abstraite (se déduit lors de la compilation à l'analyse syntaxique et sémantique.). On construit un arbre de syntaxe abstraite pour comprendre.\\
On définit la syntaxe abstraite par une grammaire. En OCamL, on réalise la syntaxe abstraite par des types construits. Il n'y a pas de parenthèses dans la syntaxe abstraite. On appelle sucre syntaxique toute construction de la syntaxe concrète qui n'existe pas dans la syntaxe abstraite.

C'est sur la syntaxe abstraite qu'on va définir la sémantique.

\subsection{Sémantiques Useless}
\subsubsection{Sémantique Axiomatique - Logique de Floyd-Hoare}
Tony Hoare, An axiomatic basis for computer programming, 1969, article le plus cité de l'histoire de l'informatique.\\
On caractérise les programmes par l'intermédiaire des propriétés satsfaites par les variables. On introduit le triplet \{$P$\} $i$ \{$Q$\} qui signifie, si $P$ est vraie avant l'instruction $i$, après, $Q$ sera vraie

\subsubsection{Sémantique Dénotationelle}
A chaque expression $e$, on associe sa définition $\left\lVert e\right\rVert $ qui est un objet représentant le calcul désigné par $e$. On définit cet objet récursivement.\\

\subsubsection{Sémantique Par Traduction}
On définit la sémantique d'un langage en le traduisant vers un langage dont la sémantique est connue. 

\subsection{Sémantique Opérationnelle}
La sémantique opérationnelle décrit l'enchaînement des calculs élémentaires qui mènent de l'expression à son résultat.\\
Il y a deux formes de sémantique opérationelle :
\begin{enumerate}
    \item La sémantique naturelle (big-steps semantics) : $e \twoheadrightarrow v$
    \item La sémantique par réduction (small steps semantics) $e \rightarrow e_{1} \rightarrow e_{2} \rightarrow \ldots \rightarrow v$
\end{enumerate}
On applique ça à Mini-ML (qui est Turing-Complet). 

\subsubsection{Sémantique Opérationnelle à Grand Pas}
On cherche à définir $e \twoheadrightarrow v$. On définit les valeurs parmi les constantes, les primitives non appliquées, les fonctions et les paires. \\
Une relation peut être définie comme la plus petite relation satisfaisant un ensemble d'axiomes notés $\overline{P}$ et des règles d'inférences (implications). On définit \textmd{Pair(n)} par $\overline{Pair(0)}$ et $\frac{Pair(n)}{Pair(n+2)}$. La plus petitre relation qui vérifie ces deux propriétés coïncide avec la propriété \og $n$ est un entier naturel pair \fg.\\
Une dérivation est un arbre dont les noeuds correspondent aux règles et les feuilles aux axiomes (les arbres croissent vers le haut). L'ensemble des dérivations possibles caractérise exactement la plus petite relation satisfaisant les règles d'inférence. \\
\begin{definition}
    On définit les variables libres d'une expression $e$, noté $fv(e)$ par récurrence sur $e$ avec :
    \begin{tabular}{rcl}
        $fv(x)$ &$=$&$\left\{x\right\}$\\
        $fv(c)$ &$=$&$\emptyset$\\
        $fv(op)$ &$=$&$\emptyset$\\
        $fv(\fun{x}{e})$ &$=$&$fv(e) \setminus \left\{x\right\}$\\
        $fv(e_{1} e_{2})$ &$=$&$fv(e_{1}) \cup fv(e_{2})$\\
        $fv((e_{1}, e_{2}))$ &$=$&$fv(e_{1}) \cup fv(e_{2})$\\
        $fv(\letin{x = e_{1}} e_{2})$ &$=$&$fv(e_{1}) \cup \left(fv(e_{2})\setminus \left\{x\right\}\right)$\\
        $fv(x)$ &$=$&$\left\{x\right\}$\\        
    \end{tabular}\\
    On défnit la substitution  de toute occurence libre de $x$ dans $e$ par $v$ définie par : 
    \begin{tabular}{rcl}
        $x[x\leftarrow v]$ &=& $v$\\
        $y[x \leftarrow v]$ &$=$& $y$ si $y\neq x$
    \end{tabular}
\end{definition}
On fait le choix d'une stratégie d'appel par valeur, i.e. l'argument est complètement évalué avant l'appel. \\
On a ici comme axiomes : $\overline{c \twoheadrightarrow c}$, $\overline{op \twoheadrightarrow op}$, $\overline{(\textmd{fun } x \rightarrow e) \twoheadrightarrow (\fun{x}{e})}$
et comme règles d'inférences : 
\[    
    \frac{e_{1} \twoheadrightarrow v_{1} \ \ e_{2} \twoheadrightarrow v_{2}}{(e_{1}, e_{2}) \twoheadrightarrow (v_{1}, v_{2})} \ \ \ \frac{e_{1} \twoheadrightarrow v_{1} \ \ e_{2}[x \leftarrow v_{1}] \twoheadrightarrow v}{let\ x  = e_{1} \textmd{ in } e_{2} \twoheadrightarrow v}
\]
et 
\[
  \frac{e_{1}\rrarrow(\fun{x}{e})\ \ e_{2} \rrarrow v_{2} \ \ e[x \leftarrow v_{2}] \rrarrow v}{e_{1}\ e_{2} \rrarrow v}
\]
On ajoute ensuite des règles pour les primitives, dépendant de la forme de chacune, e.g. : 
\[
  \frac{e_{1} \rrarrow + \ \ e_{2} \rrarrow (n_{1}, n_{2})\ \ n = n_{1} + n_{2}}{e_{1}\ e_{2} \rrarrow n}  
\]

Partant, on peut montrer qu'un programme s'évalue en une valeur en écrivant l'arbre de dérivation de celui-ci. \\
\begin{remark}
    Il existe des expressions sans valeur : $e = 1 2$ par exemple.
\end{remark}

On peut établir une propriété d'une relation définie par un ensemble de règles d'inférence, en raisonnant par induction sur la dérivation. Cela signifie par récurrence structurelle.
\begin{proposition}
    Si $e\twoheadrightarrow v$, alors $v$ est valeur. De plus si $e$ est close alors $v$ l'est également.
\end{proposition}
\begin{proof}
    Par induction : $\frac{e_{1} \twoheadrightarrow (\fun{x}{e}) \ \ e_{2} \twoheadrightarrow v_{2} \ \ e[x \leftarrow v_{2}] \twoheadrightarrow v}{e_{1} e_{2} \twoheadrightarrow v}$.
\end{proof}
\begin{proposition}
    Si $e \twoheadrightarrow v$ et $e \twoheadrightarrow v^{'}$, alors $v = v'$.
\end{proposition}
\begin{proof}
    Par induction. 
\end{proof}
\begin{remark}
    On a donc définit une fonction plus qu'une relation. 
\end{remark}

\subsubsection{Sémantique à Petits Pas}
La sémantique opérationnelle à petits pas remédie aux problèmes de programmes qui ne terminent pas, en introduisant une notion d'étape élémentaire de calcul $e_{1} \rightarrow e_{2}$\\
On commence par définir une relation $\rightarrow^{\epsilon}$ correspondant à une réduction en tête, au sommet de l'expression, par exemple : $(\textmd{fun } x\rightarrow e)\ v \rightarrow^{\epsilon} e[x \leftarrow v]$
On se donne également des règles pour les primitives. On réduit en profondeur en introduisant la règle d'inférence : $\frac{e_{1}\rightarrow^{\epsilon} e_{2}}{E(e_{1})\rightarrow E(e_{2})}$ où $E$ est un contexte défini par la grammaire suivante :
\begin{tabular}{crl}
    $E$ &$::=$& $\square$\\
    &|& $E e$\\
    &|& $v E$\\
    &|& $\letin{x = E} e$\\
    &|& $(E, e)$\\
    &|& $(v, E)$\\
\end{tabular}\\
Un Contexte est un terme à trou où $\square$ représente le trou. $E(e)$ dénote le contexte $E$ dans lequel $\square$ a été remplacé par $e$. La règle d'inférence permet donc d'évaluer une sous-expression. Tels que définis, les contextes impliquent ici une évaluation en appel par valeur et de gauche à droite. \\
On note $\rightarrow^{*}$ la cloture réflexive et transitive de $\rightarrow$.
\begin{definition}
    On appelle forme normale toute expression $e$ telle qu'il n'existe pas $e^{'}$ telle que : $e \rightarrow e^{'}$
\end{definition}

\subsubsection{Equivalence des Sémantiques}
\begin{theorem}
    Les deux sémantiques opérationnelles sont équivalentes pour les expressions dont l'évaluation termine sur une valeur i.e. :
    \[
        e \rrarrow v \Leftrightarrow e \rightarrow^{*} v    
    \]    
\end{theorem}
\begin{proof}
    \begin{lemma}[Passage au contexte des réductions]
        Supposons $e \rightarrow e'$, alors :        
        \begin{enumerate}
            \item $e e_{2} \rightarrow e^{'} e_{2}$
            \item $v e \rightarrow v e^{'}$
            \item $\letin{x = e} e_{2} \rightarrow \letin{x = e'} e_{2}$
        \end{enumerate}
    \end{lemma}
    \begin{itemize}
        \item $(\Rightarrow)$ On procède par induction sur la dérivation. 
        \item $(\Leftarrow)$ :
        \begin{lemma}[Evaluation des Valeurs]
           On a $v \rrarrow v$.
        \end{lemma}
        \begin{lemma}
            Si $e \rightarrow e'$ et $e' \rrarrow v$ alors $e \rrarrow v$.
        \end{lemma}
        \begin{proof}
            On commence par les réductions de tête, puis on procède par induction aux applications de contexte. 
        \end{proof}
        On a alors, par récurrence sur le nombre de pas, l'implication souhaitée. 
    \end{itemize}
\end{proof}

\subsubsection{Langages Impératifs}
Pour un langage impératif les sémantiques ci-dessus sont insuffisantes. On associe alors typiquement un état $S$ à l'expression évaluée. L'état peut être décomposé en plusieurs éléments pour modéliser par exemple une pile (des variables locales), des tas... 

\section{Interprète}
    On peut programmer un interprète en suivant les règles de la sémantique naturelle. On se donne un type pour la syntaxe abstraite des expressions et on définit une fonction correspondant à la relation $\twoheadrightarrow$\\
    Un interprète renvoie la (ou les) valeur(s) d'une expression, souvent récursivement.\\
    On peut éviter l'opération de substitution, en interprétant l'expression $e$ à l'aide d'un environnement donnant la valeur courante de chaque variable (un dictionnaire). Ceci pose problème car le résultat de $\textmd{let } x = 1 \textmd{ in fun } y \rightarrow +(x, y)$ est une fonction qui doit \og mémoriser \fg que $x = 1$.\\
    On utilise alors le module \textmd{Map} pour les environnements (c'est une \textit{fermeture}). On représente alors la valeur d'une fonction avec son environnement. \\
    Pour un interprète de la sémantique à petits pas, il vaut mieux utiliser un \textit{zipper} que de recalculer le contexte tout le temps. 

\part[Analyse Lexicale]{Cours 3 : 13/10}
\localtableofcontents
\section*{Introduction}
L'objectif est de partir du code source, une suite de caractère, pour obtenir une suite de lexèmes plus compréhensible et simple à analyse syntaxiquement

\section{Blancs}
Les blancs (espace, retour chariot, tabulation) jouent un rôle dans l'analyse lexicale, car ils permettent de séparer deux lexèmes. De nombreux blancs sont inutiles e.g. \textmd{x + 1}, et seront ignorés.\\
Les conventions diffèrent selon les langages et certains des caractères blancs peuvent être significatifs, par exemple l'indentation en python ou en Haskell, ou les retours chariots transformés en points-virgules comme en python. Les commentaires jouent le rôle de blancs.

\section{Outils pour l'analyse lexicale}
On va utiliser des expressions régulières pour décrire les lexèmes et des automates finis pour les reconnaître. On exploite en particulier la capacité à construire un automate partant d'une ou plusieurs expressions régulières.

\subsection[Expressions Régulières et Automates Finis]{Expressions Régulières et Automates Finis\footnote{Voir Cours de LFCC}} 
%TODO: ajouter un lien vers le cours. Faire un seul poly complet ? 

\subsubsection{Expressions Régulières}
\begin{definition}[Syntaxe]
    On définit la syntaxe des expressions régulières :
\begin{center}
    \begin{tabular}{c@{$\mid$}c}
        $r = $& $\emptyset$\\
        &$\epsilon$\\
        &$a \in \Sigma$\\
        &$r \cdot r$\\
        &$r + r$\\
        &$r\star$\\    
    \end{tabular}    
\end{center} 
\end{definition}

\begin{definition}[Sémantique]
    On définit alors la sémantique basée sur cette syntaxe par les langages rationnels : 
    \begin{center}
        \begin{tabular}{c@{ = }c}
            $L(\emptyset)$ &$\emptyset$\\
            $L(a)$ &$\left\{a\right\}$\\
            $L(r_{1}r_{2})$ &$L(r_{1}) \cdot L(r_{2})$\\
            $L(r_{1} + r_{2})$ &$L(r_{1}) \cup L(r_{2})$\\
            $L(r\star)$ &$\bigcup_{n \in \N} L^{n}(r)$        
        \end{tabular}
    \end{center} 
\end{definition}

Pour les constantes flottantes de CamL on a par exemple, si $d = 0 | 1 | \ldots | 9$ :
\[
    d\ d\star(.d\star \mid (\epsilon \mid .d\star)(e \mid E)(\epsilon \mid + \mid -)\ d\ d\star)  
\]
On peut alors écrire un algorithme pour savoir si une suite de caractère appartient à une regexp.
\begin{definition}[Dérivée de Brzozowski]
    On pose, pour $r$ une regexp et $c \in \Sigma$ : $\delta(r, c) = \left\{w \mid cw \in L(r)\right\}$
\end{definition}

\subsubsection{Automates Finis}
\begin{definition}[Syntaxe]
    Un automate fini est un quintuplet $(Q, \Sigma, I, F, T)$ où :
    \begin{itemize}
        \item $Q$ est un ensemble fini d'états
        \item $\Sigma$ est un ensemble fini appelé alphabets
        \item $I \subseteq Q$ est un ensemble d'états initiaux
        \item $F \subseteq Q$ est un ensemble d'états finaux
        \item $T \subseteq Q \times \Sigma \times Q$ est un ensemble de transitions
    \end{itemize}
\end{definition}

\begin{theorem}[De Kleene]
    Les expressions régulières et les automates finis définissent les mêmes langages. 
\end{theorem}
\begin{proof}
    Voir Cours de LFCC
\end{proof}

\subsection{Analyseur Lexical}

\subsubsection{Principe}

Un analyseur lexical est un automate fini pour la réunion de toutes les expressions régulières définissant les lexèmes.
Le fonctionnement de l'analyseur lexical est différent de la simple reconnaissance d'un mot par un automate car : 
\begin{itemize}
    \item Il faut décomposer un mot (le source) en une suite de mots reconnus
    \item Il peut y avoir des ambiguïtés
    \item Il faut construire les lex`emes (les états finaux contiennent des actions)
\end{itemize}

\paragraph*{Ambiguïtés}
Le mot \textmd{funx} est reconnu par l'expression régulière des identificateurs mais contient un préfixe reconnu par une autre expression régulière (\textmd{fun}) : $\Rightarrow$ On choisit de reconnaître le lexème le plus long possible.\\
Le mot \textmd{fun} est reconnu par la regexp du mot clef \textmd{fun} mais aussi par celle des identificateurs : $\Rightarrow$ On classe les lexèmes par ordre de priorité.

\paragraph*{Retour en arrière}
Un analyseur va échouer sur l'entrée $abc$ avec les trois regexp $a, ab, bc$.
L'analyseur lexical doit donc mémoriser le dernier état final rencontré, le cas échéant.\\

Lorqu'il n'y a plus de transition possible dans l'automate, de deux choses l'une :
\begin{itemize}
    \item Soit aucun état final mémorisé : échec de l'analyse lexicale
    \item Soit on a lu le préfixe $wv$ de l'entrée, avec $w$ le lexème reconnu par le dernier état final recontré : on renvoie $w$ et l'analyse lexicale redémarre avec $v$ préfixé au reste de l'entrée
\end{itemize}
En pratique, on va renvoyer dans l'analyseur lexical une fonction de calcul du prochain lexème, puisque l'analyse lexicale est faite pour l'analyse syntaxique 
%TODO: ajouter la ref du cours d'analyse syntaxique

\subsubsection{Construction}
\paragraph*{L'automate de Thompson}
On construit par induction un automate compatible. 

\paragraph*{L'automate de Berry-Sethi}
On met en correspondance les lettres d'un mot reconnu et celles apparaissant dans la regexp : 
On distingue les différentes lettres de la regexp puis on construit un automate dont les états sont des ensembles de lettres. 
Pour construire les transitions de $s_{1}$ à $s_{2}$, on détermine les lettres qui peuvent apparaître après une autre dans un mot reconnu : \textmd{follow}. Pour calculer \textmd{follow}, on a besoin de savoir calculer les premières et dernières lettres d'un mot reconnu (\textmd{first} et \textmd{last}). On a alors besoin d'une dernière notion : \textmd{null}, est-ce que $\epsilon$ appartient au langage reconnu. On obtient : 
\begin{center}
    \begin{tabular}{c@{ = }c}
        \toprule
        $\textmd{null}(\emptyset)$ & \textmd{false}\\
        $\textmd{null}(\epsilon)$ & \textmd{true}\\
        $\textmd{null}(a)$ & \textmd{false}\\
        $\textmd{null}(r_{1}r_{2})$ & $\textmd{null}(r_{1}) \land  \textmd{null}(r_{2})$\\
        $\textmd{null}(r_{1}\mid r_{2})$ & $\textmd{null}(r_{1}) \lor  \textmd{null}(r_{2})$\\
        $\textmd{null}(r\star)$ & \textmd{true}\\
        \midrule
        \multicolumn{2}{c}{On en déduit : }\\
        \midrule
        $\textmd{first}(\emptyset)$ & $\emptyset$\\
        $\textmd{first}(\epsilon)$ & $\emptyset$\\
        $\textmd{first}(a)$ & $\left\{a\right\}$\\
        $\textmd{first}(r_{1}r_{2})$ & $\textmd{first}(r_{1}) \cup \textmd{first}(r_{2})$ \text{ si }$\textmd{null}(r_{1})$\\
        & $\textmd{first}(r_{1})$ sinon\\
        $\textmd{first}(r_{1}\mid r_{2})$ & $\textmd{first}(r_{1}) \cup \textmd{first}(r_{2})$\\
        $\textmd{first}(r\star)$ & $\textmd{first}(r)$\\
        \midrule
        \multicolumn{2}{c}{On définit \textmd{last} de même}\\
        \midrule
        $\textmd{follow}(c, \emptyset)$ & $\emptyset$\\
        $\textmd{follow}(c, \epsilon)$ & $\emptyset$\\
        $\textmd{follow}(c, a)$ & $\emptyset$\\
        $\textmd{follow}(c, r_{1}r_{2})$ & $\textmd{follow}(c, r_{1}) \cup \textmd{follow}(c, r_{2}) \cup \textmd{first}(r_{2})$ si $c \in \textmd{last}(r_{1})$\\
        & $\textmd{follow}(c, r_{1}) \cup \textmd{follow}(c, r_{2})$ sinon\\
        $\textmd{follow}(c, r_{1} \mid r_{2})$ & $\textmd{follow}(c, r_{1}) \cup \textmd{follow}(c, r_{2})$\\
        $\textmd{follow}(c, r\star)$ & $\textmd{follow}(c, r) \cup \textmd{first}(r)$ si $c\in \textmd{last}(r)$\\
        &$\textmd{follow}(c, r)$ sinon\\
        \bottomrule
    \end{tabular}
\end{center}
On construit alors l'automate reconnaissant $r$ en ajoutant $\#$ à la fin de $r$ : 
\begin{enumerate}
    \item L'état initial est l'ensemble $\textmd{first}(r\#)$.
    \item Tant qu'il existe un état $s$ dont on doit calculer les transitions, pour chaque $c$ de l'alphabet, on pose $s^{'}$ l'état $\bigcup_{c_{i} \in s} \textmd{follow}(c_{i}, r\#)$
    \item Les états acceptants sont ceux contenant $\#$
\end{enumerate}

\section{L'outil \textmd{ocamllex}}
\subsection{Analyseur Lexical en \textmd{ocamllex}}
Un fichier \textmd{ocamllex} porte le suffixe \textmd{.mll} et a la forme suivante : 
\begin{itemize}
    \item Code OCamL arbitraire
    \item $\textmd{rule } f_{1} = \textmd{parse} \mid \textmd{regexp1 } \{\textmd{action 1}\}$ 
    \item \dots
    \item Code OcamL arbitraire
\end{itemize}
A la compilation par \textmd{ocamllex file.mll}, on construit un fichier OCamL contenant des fonctions de types $\textmd{Lexing.lexbuf} \rightarrow \textmd{type}$ où le type de sortie dépend de l'action dans la fonction. \\

Les regexp en \textmd{ocamllex} s'écrivent sous la forme : 
\begin{center}
    \begin{tabular}{>{\textmd{}}ll}
        \toprule
        \_  & n'importe quel caractère\\
        'a' & le caractère \textmd{'a'}\\
        "foobar" & la chaîne \textmd{"foobar"} (en particulier $\epsilon = ""$)\\
        \text{[}caractères\text{]} & ensemble de caractères\\
        \text{[}\^{}caractères\text{]} & complémentaire d'un ensemble de caractères\\
        $r_{1} \mid r_{2}$ & alternative \\
        $r_{1}r_{2}$ & concaténation \\
        $r *$ & étoile\\
        $r + $ & une ou plusieurs occurences de $r$, i.e. $r r\star$\\
        $r?$ & au plus une occurence de $r$\\
        eof & fin du fichier\\
        \bottomrule         
    \end{tabular}
\end{center}
Pour remplacer la reconnaissance du lexème le plus long par celui le plus court, remplacer \textmd{parse} par \textmd{shortest}.\\
A longueur égale, c'est la règle qui apparaît en premier qui l'emporte. \\
On peut nommer la chaîne reconnue, ou des sous-chaînes reconnues par des sous-experssions régulières, à l'aide de la construction \textmd{as}.\\
On peut dans une action, rappeler récursivement l'analyseur lexical ou l'un des autres analyseurs simultanément définis. Le tampon d'analyse lexical doit être passé en argument, il est contenu dans une variable appelée \textmd{lexbuf}. Ceci est utile pour séparer les blancs, ou reconnaître les commentaires, même imbriqués. \\

Par défaut \textmd{ocamllex} contruit l'automate dans une table interprétée à l'exécution, mais l'option \textmd{-ml} construit du code CamL pur. 

\subsection{Efficacité}
Pour des raisons de stockage, et même en utilisant une table, l'automate peut prendre beaucoup de place. Il est donc préférable d'utiliser une seule expression régulière pour les identificateurs et les mots-clefs, puis de les séparer ensuite grâce à une table des mots-clefs.\\
On peut de même ne stocker que les caractères en minuscule pour être insensible à la casse.

\subsection{D'autres utilisations \textmd{ocamllex}}
On peut utiliser $\textmd{ocamllex}$ pour :
\begin{enumerate}
    \item Réunir plusieurs lignes vides consécutives en une seule
    \item Compter les occurences d'un mot dans un texte
    \item Un petit traducteur OCamL vers HTML pour embellir le source mis en ligne (mettre les mots-clefs en vert, les commentaires en rouge, numéroter les lignes \dots), le tout en moins de 100 lignes de code.
\end{enumerate}
\end{document}