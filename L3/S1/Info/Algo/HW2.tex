\documentclass{Cours}
\date{\today}
\author{Matthieu Boyer}
\title{Homework Assignment 2}

\begin{document}
    \section{Exercise 1}
        \subsection{Question 1}
            For $i, j$ in $\lvert 1, n \rvert^{2}$, we have $AB_{i, j} = A_{i*}B_{*j} = \sum_{k = 1}^{n} A_{i, k}B_{k, j}$, thus $AB$ is computed by computed, for all $i, j$ the product $A_{i,k}B_{k,j}$ and thus uses at most $\sum_{k = 1}^{n} a_{k}b_{k}$ multiplications.

        \subsection{Question 2}
            The number of multiplications and additions is two times the number of multiplications. We just need to get a majoration of the number of multiplications. Yet, since $a_{k} \leq n$ for all $k$, $\sum_{k = 1}^{n} a_{k} b_{k} \leq n \sum_{k=1}^{n}b_{k} = mn$. Then the number of multiplications and additions required is $\O(mn)$.

        \subsection{Question 3}
            Multiplying a matrix in $\mathcal{M}_{ap, bp}$ by a matrix $\mathcal{M}_{bp, cp}$ can, by seeing the matrices as block matrices, be seen as multiplying two matrices in $\mathcal{M}_{p}$ the number of times we need to compute the product of matrix in $\mathcal{M}_{a,b}$ by a matrix  in $\mathcal{M}_{b, c}$ :
            \[
                \left(\begin{matrix}
                    \alpha_{1, 1} & \ldots & \alpha_{1, bp}\\
                    \vdots & & \vdots\\
                    \alpha_{ap, 1} & \ldots & \alpha_{ap, bp}
                \end{matrix}\right)
                = \left(
                \begin{matrix}
                    A_{1, 1} & \ldots & A_{1, b}\\
                    \vdots & & \vdots\\
                    A_{a, 1} & \ldots & A_{a, b}
                \end{matrix}\right)
                \text{ where } A_{i, j} = \left(
                    \begin{matrix}
                        \alpha_{i p + 1, j p + 1} & \ldots & \alpha_{i p + 1, j (p + 1)}\\
                        \vdots & & \vdots\\
                        \alpha_{i (p + 1), j p + 1} & \ldots & \alpha_{i (p + 1), j (p + 1)}
                    \end{matrix}                    
                    \right) \in \mathcal{M}_{p}
            \]  
            Thus, we can multiply a matrix in $\mathcal{M}_{ap, bp}$ by a matrix $\mathcal{M}_{bp, cp}$ in $M(a, b, c)M(p, p, p)$ multiplications. Thus : 
            \[
                M(ap, bp, cp) \leq M(a, b, c)M(p, p, p)
            \]
            
        \subsection{Question 4}
            \begin{itemize}
                \item If $0 \leq r \leq \alpha$: $w(1, r, 1)$ is the smallest number $k$ such that $M(n, n^{r}, n) = \O(n^{k + o(1)})$. But, again by seeing $A$ an $n\times n^{\alpha}$ matrix as a $n\times n^{r}$ matrix next to a $n, n^{\alpha} - n^{r}$ matrix and same for $B$, we get $M(1, r, 1) \leq M(1, \alpha, 1)$ and thus $w(1, r, 1) \leq w(1, \alpha, 1) = 2$.
                \item If $\alpha \leq r \leq 1$ : by seeing a $n \times n^{r}$ matrix $A$ as a $n^{\frac{1 - r}{1 - \alpha}} \times n^{\frac{\left(1 - r\right)\alpha}{1 - \alpha}}$ bloc matrix with blocks of size $n^{\frac{r - \alpha}{1 - \alpha }}\times n^{\frac{r - \alpha}{1 - \alpha}}$ and applying the reasoning from 3. we get that : 
                \[
                    \begin{aligned}
                        M(n, n^{r}, n) = &\ M\left(n^{\frac{1 - r}{1 - \alpha}} \cdot n^{\frac{r - \alpha}{1 - \alpha }}, n^{\frac{\left(1 - r\right)\alpha}{1 - \alpha}}\right.\\ 
                        &\ \left.\times n^{\frac{r - \alpha}{1 - \alpha}}, n^{\frac{1 - r}{1 - \alpha}} \cdot n^{\frac{r - \alpha}{1 - \alpha }}\right)\\
                         \leq&\  M\left(n^{\frac{1 - r}{1 - \alpha}}, n^{\frac{(1 - r)\alpha}{1 - \alpha}}, n^{\frac{1 - r}{1 - \alpha}}\right)\\
                        &\ \times M\left(n^{\frac{r - \alpha}{1 - \alpha}}, n^{\frac{r - \alpha}{1 - \alpha}}, n^{\frac{r - \alpha}{1 - \alpha}}\right)\\
                        = &\ \O\left(\left(n^{\frac{1 - r}{1 - \alpha}}\right)^{{w(1, \alpha, 1)}}\left(n^{\frac{r - \alpha}{1 - \alpha}}\right)^{\omega}\right)\\
                        = &\ \O\left(n^{\frac{2 * (1 - r) + \left(r - \alpha\right) \omega}{1 - \alpha}}\right)
                    \end{aligned}      
                \]
                The first big O equality comes from a substitution in $M(n, n^{\alpha}, n) = \O(n^{w(1, \alpha, 1)})$ of $n$ by $n^{\frac{1 - r}{1 - \alpha}}$.
                We obtain : 
                \[
                    \begin{aligned}
                        w(1, r, 1)  \leq &\ \frac{2 \times \left(1 - r\right) + \left(r - \alpha\right)\omega}{1 - \alpha}\\
                        = &\ \frac{2 \times \left(1 - \alpha\right) + 2 \times \left(\alpha - r\right) + \left(r - \alpha\right) \omega}{1 - \alpha}\\
                        = &\ 2 + \frac{\omega \times \left(\alpha - r\right) - 2 \times \left(\alpha - r\right)}{1 - \alpha}\\
                        = &\ 2 + \beta(r - \alpha)
                    \end{aligned}
                \]
            \end{itemize}
            
        \subsection{Question 5}
            Let $1 \leq l \leq n$, $a_{k}, b_{k}$ such that $a_{k}b_{k}$ is decreasing.
            If $l = 1$, the result is trivial. 
        
            Consider for $i \in \left\llbracket 1, l - 1\right\rrbracket$ the quantity $a_{i}b_{j} + a_{j}b_{i}$, we get :
            \begin{itemize}
                \item If $a_{i} > a_{j}$ : $a_{i}b_{j} + a_{j}b_{i} > a_{j}b_{j}$
                \item Else : $a_{i}b_{j} + a_{j}b_{i} > a_{i}b_{i} > a_{j}b_{j}$ by hypothesis.
            \end{itemize}

            Then we get : 
            \[\sum_{j = i + 1}^{n} a_{i}b_{j} + a_{j}b_{i} > \sum_{k = l}^{n} a_{k}b_{k}\] since the $a_{k}$ and $b_{k}$ are positive.
            By summing :  
            \[\sum_{i = 1}^{l -1}\sum_{j = i + 1}^{n} a_{i}b_{j} + a_{j}b_{i} > l\sum_{k = l}^{n} a_{k}b_{k}\]
            But : 
            \[m_{1}m_{2} = \sum_{i = 1}^{n}a_{i} \sum_{j = 1}^{n}b_{j} = \sum_{i = 1}^{n}\sum_{j = i + 1}^{n}a_{i}b_{l} > \sum_{i = 1}^{l - 1}\sum_{j = i + 1}^{n}a_{i}b_{j}\]
            Thus :
            \[\sum_{k = l}^{n} a_{k}b_{k} < \frac{m_{1}m_{2}}{l}\]

        \subsection{Question 6}
        We will first prove correctness by induction : \\
        Initialization : If $m^{2} \leq n^{2}$, it is clear.\\
        Heredity : Since $\pi$ is bijective, $I\sqcup J = \llbracket 1, n \rrbracket$, we get that no two columns in $A_{*I}$ and $A_{*J}$ have an element in the same spot. Then, if $i, j \in \llbracket 1, n \rrbracket$, we get : 
        \[
            \left[AB\right]_{i, j} = \sum_{k\in \llbracket 1, n\rrbracket} a_{i, k}b_{k, j} = \sum_{k\in I}a_{i, k}b_{k,j} + \sum_{k \in J}a_{i,k}b_{k,j} = \left[A_{*I}B_{I*}\right]_{i, j} + \left[A_{*J}B_{J*}\right]_{i, j}
        \]
        Hence, the algorithm is correct.

        Then, for the complexity we get that :
        \begin{itemize}
            \item If $m \leq n$, the algorithm runs in $\O(mn)$.
            \item Else, its complexity is the sum of three steps :
            \begin{itemize}
                \item Calculating $C_{1} = A_{*I}B_{I*}$ takes $M(n, l, n) = \O(n^{w(1, r, 1) + o(1)})$ multplications for $r = \frac{\ln l}{\ln n} < 1$.
                \item From question 5), calculating $C_{2} = A_{*J}B_{J*}$ takes at most $\frac{m^{2}}{l}$ multiplications. 
                \item Summing the results takes $\O(n^{2})$ operations.
            \end{itemize}
        \end{itemize}

        We obtain a time complexity in the worst case in $\O(n^{w(1, r, 1) + o(1)} + \frac{m^{2}}{l} + n^{2})$, assuming that $m^{2} > n^{2}$.
        In that case, we let $l = m^{\frac{2}{\beta + 1}}n^{\frac{\alpha\beta - 2}{\beta + 1}}$.
        Then, the computation of $C_{1}$ takes $\O(n^{w(1, r, 1) + o(1)}) = \O(n^{2 + \beta\left(\frac{\ln l}{\ln n} - \alpha\right)})$ from question 4. Then, we get : 
        \[
            \begin{aligned}
                n^{2 + \beta\left(\frac{\ln l}{\ln n} - \alpha\right)} =& n^{2 - \alpha\beta} l^{\beta} \\
                =& n^{2 - \alpha\beta}m^{\frac{2\beta}{\beta + 1}}n^{\frac{\alpha\beta^{2} - 2\beta}{\beta + 1}}\\
                =& m^{\frac{2\beta}{\beta + 1}}n^{2 - \alpha\beta + \frac{\alpha\beta^{2}}{\beta + 1} - \frac{2 \beta}{\beta + 1}}\\
                =& m^{\frac{2\beta}{\beta + 1}}n^{\frac{2}{\beta+1} + \frac{\alpha\beta^{2} - \alpha\beta\left(\beta + 1\right)}{\beta + 1}}\\
                =& m^{\frac{2\beta}{\beta + 1}}n^{\frac{2 - \alpha \beta}{\beta + 1}}\\
            \end{aligned}
        \]

        Moreover, since the computation of $C_{2}$ is done in $\O(\frac{m^{2}{l}})$, replacing $l$ by its value : 
        \[
            \frac{m^{2}}{l} = m^{2 - \frac{2}{\beta + 1}}n^{\frac{2}{\beta + 1} - \frac{\alpha \beta}{\beta + 1}} = m^{\frac{2\beta}{\beta + 1}}n^{\frac{2 - \alpha\beta}{\beta + 1}}
        \]
            
        In the end, we get a total complexity in : 
        \[
            \O\left(m^{\frac{2\beta}{\beta + 1}}n^{\frac{2 - \alpha \beta}{\beta + 1}} + o(1)\right) + \O\left(m^{\frac{2\beta}{\beta + 1}}n^{\frac{2 - \alpha \beta}{\beta + 1}}\right) + \O(n^{2}) = \O\left(m^{\frac{2\beta}{\beta + 1}}n^{\frac{2 - \alpha \beta}{\beta + 1} + o(1)}\right)
        \]

        Using the given values for $\alpha$ and $\beta$, this time complexity is in \[\O(m^{0.7}n^{1.21} + n^{2 + o(1)})\]   

    \section{Exercise 2}
        \subsection{Question 1}
            Since concatenation is associative, we can look at the concatenation of a list of length $n$ as the concatenation of the numbers resulting of the concatenation of any partition $A_{1}, \ldots, A_{d}$ of the list such that if $i < j$, $a_{j} \in A_{k} \Rightarrow a_{i} \in A_{l}$ where $l \leq k$.
            
            Since for one and two elements, it is clear that results hold, we only need to cover the case of an insertion. Indeed, if sorting by insertion gives a correct result, then any sorting algorithm gives a correct result. Suppose that a list with $n$ elements $a_{0}, \ldots, a_{n- 1}$ is sorted using the order defined. Let $a_{n}$ be another number, and suppose it is inserted between $a_{i}$ and $a_{i + 1}$ by insertion sort.
            Then, suppose that the result we obtain is not the right one. We return to the case of three elements, since the final concatenation can be seen as the one of the results of the concatenation of $a_{0}, \ldots, a_{j}$, $a_{n}$ and $a_{j + 1}, \ldots, a_{n - 1}$.  
\end{document}